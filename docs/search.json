[
  {
    "objectID": "teaching.html",
    "href": "teaching.html",
    "title": "Teaching",
    "section": "",
    "text": "Tutorials\nSurvival analysis in R: A detailed tutorial on conducting survival analyses in R, including an introduction to the basics of survival analysis, landmark analyses and time-dependent covariates, competing risks, and a selection of advanced topics.\n\n\nCourses\nR for Cleveland Clinic Molecular Medicine PhD program: Five one-hour sessions on the basics of R, followed by two two-hour sessions introducing biostatistics and epidemiology methods in R."
  },
  {
    "objectID": "talks/2025-umass-r-cafe/slides.html#hello",
    "href": "talks/2025-umass-r-cafe/slides.html#hello",
    "title": "Making your workflow reproducible",
    "section": "Hello",
    "text": "Hello\n\n\nWho am I?\nAssociate Staff Biostatistician at the Cleveland Clinic in the Department of Quantitative Health Sciences and the Taussig Cancer Institute.\n\n\nApplied cancer biostatistics and methods research in early phase oncology clinical trial design and methods for retrospective data analyses.\nCheckout my website for more."
  },
  {
    "objectID": "talks/2025-umass-r-cafe/slides.html#why-am-i-here",
    "href": "talks/2025-umass-r-cafe/slides.html#why-am-i-here",
    "title": "Making your workflow reproducible",
    "section": "Why am I here?",
    "text": "Why am I here?\nGood question.\n\nThis is not my area of expertise\nBut I have been doing data analysis projects in R for 15+ years\nAnd I’ve learned a few things along the way\nIf you are an expert, chime in anytime!"
  },
  {
    "objectID": "talks/2025-umass-r-cafe/slides.html#what-will-i-cover-today",
    "href": "talks/2025-umass-r-cafe/slides.html#what-will-i-cover-today",
    "title": "Making your workflow reproducible",
    "section": "What will I cover today?",
    "text": "What will I cover today?\nHow I try to make my project workflow reproducible, including:\n\n{starter} to create standard project frameworks\nFolder structure and naming\nRStudio projects and {here} package for portability\nQuarto for reproducible reporting\n{renv} for reproducible environments"
  },
  {
    "objectID": "talks/2025-umass-r-cafe/slides.html#context",
    "href": "talks/2025-umass-r-cafe/slides.html#context",
    "title": "Making your workflow reproducible",
    "section": "Context",
    "text": "Context\nEverything here evolved in the context of the work I do and how I do it.\n\nCollaborate with doctors on clinical research projects: they send me data, I analyze it\nWork independently as the only statistician/programmer for a given project\nPatient data is sensitive\n2 and 3 mean nothing goes on GitHub\n2 also means that my interest in reproducibility is for future me and for sound science"
  },
  {
    "objectID": "talks/2025-umass-r-cafe/slides.html#the-starter-package",
    "href": "talks/2025-umass-r-cafe/slides.html#the-starter-package",
    "title": "Making your workflow reproducible",
    "section": "The {starter} package",
    "text": "The {starter} package\n\n\n\n\n\n“Provides a toolkit for starting new projects”"
  },
  {
    "objectID": "talks/2025-umass-r-cafe/slides.html#using-starter-with-default-settings",
    "href": "talks/2025-umass-r-cafe/slides.html#using-starter-with-default-settings",
    "title": "Making your workflow reproducible",
    "section": "Using {starter} with default settings",
    "text": "Using {starter} with default settings\n\n# install.packages(\"starter\") \n\nstarter::create_project(\n  path = fs::path(tempdir(), \"My Project Folder\"),\n  open = FALSE # don't open project in new RStudio session\n)\n\n✔ Using \"Default Project Template\" template\n\n\n✔ Writing folder 'C:/Users/zabore2/AppData/Local/Temp/Rtmp4AN2BX/My Project Folder'\n\n\n✔ Writing files \"README.md\", \".gitignore\", \"My Project Folder.Rproj\", and \".Rprofile\"\n\n\n✔ Initialising Git repo\n\n\n✔ Initialising renv project\n\n\n- Lockfile written to \"C:/Users/zabore2/AppData/Local/Temp/Rtmp4AN2BX/My Project Folder/renv.lock\".\n- renv infrastructure has been generated for project \"C:/Users/zabore2/AppData/Local/Temp/Rtmp4AN2BX/My Project Folder\"."
  },
  {
    "objectID": "talks/2025-umass-r-cafe/slides.html#resulting-project-structure",
    "href": "talks/2025-umass-r-cafe/slides.html#resulting-project-structure",
    "title": "Making your workflow reproducible",
    "section": "Resulting project structure",
    "text": "Resulting project structure"
  },
  {
    "objectID": "talks/2025-umass-r-cafe/slides.html#custom-starter-templates",
    "href": "talks/2025-umass-r-cafe/slides.html#custom-starter-templates",
    "title": "Making your workflow reproducible",
    "section": "Custom {starter} templates",
    "text": "Custom {starter} templates\nThe default is a great start, but I want a bit more:\n\nShell code files\nInclude Word reference document for Quarto\n\n\nSee the {starter} website for details on creating custom templates.\n\nThe R script that created my custom template is in my personal R package on GitHub here."
  },
  {
    "objectID": "talks/2025-umass-r-cafe/slides.html#using-starter-with-my-personal-template",
    "href": "talks/2025-umass-r-cafe/slides.html#using-starter-with-my-personal-template",
    "title": "Making your workflow reproducible",
    "section": "Using {starter} with my personal template",
    "text": "Using {starter} with my personal template\n\n# devtools::install_github(\"zabore/ezfun\") \n\nstarter::create_project(\n  path = fs::path(tempdir(), \"example-custom-project\"),\n  template = ezfun::ez_analysis_template,\n  open = FALSE\n)\n\n✔ Using \"EZ Analysis Template\" template\n\n\n✔ Writing folder 'C:/Users/zabore2/AppData/Local/Temp/Rtmp4AN2BX/example-custom-project'\n\n\n✔ Creating 'C:/Users/zabore2/AppData/Local/Temp/Rtmp4AN2BX/example-custom-project/code'\n\n\n✔ Creating 'C:/Users/zabore2/AppData/Local/Temp/Rtmp4AN2BX/example-custom-project/code/templates'\n\n\n✔ Writing files \"README.md\", \".gitignore\", \"example-custom-project.Rproj\", \".Rprofile\", \"code/example-custom-project-munge.R\", \"code/example-custom-project-report.qmd\", and \"code/templates/doc_template.docx\"\n\n\n✔ Initialising Git repo\n\n\n✔ Initialising renv project\n\n\n- Lockfile written to \"C:/Users/zabore2/AppData/Local/Temp/Rtmp4AN2BX/example-custom-project/renv.lock\".\n- renv infrastructure has been generated for project \"C:/Users/zabore2/AppData/Local/Temp/Rtmp4AN2BX/example-custom-project\"."
  },
  {
    "objectID": "talks/2025-umass-r-cafe/slides.html#resulting-custom-project-structure",
    "href": "talks/2025-umass-r-cafe/slides.html#resulting-custom-project-structure",
    "title": "Making your workflow reproducible",
    "section": "Resulting custom project structure",
    "text": "Resulting custom project structure"
  },
  {
    "objectID": "talks/2025-umass-r-cafe/slides.html#structure-inside-the-code-folder",
    "href": "talks/2025-umass-r-cafe/slides.html#structure-inside-the-code-folder",
    "title": "Making your workflow reproducible",
    "section": "Structure inside the code folder",
    "text": "Structure inside the code folder"
  },
  {
    "objectID": "talks/2025-umass-r-cafe/slides.html#munge-file-template",
    "href": "talks/2025-umass-r-cafe/slides.html#munge-file-template",
    "title": "Making your workflow reproducible",
    "section": "Munge file template",
    "text": "Munge file template\nUsed for data cleaning and pre-processing"
  },
  {
    "objectID": "talks/2025-umass-r-cafe/slides.html#quarto-file-template",
    "href": "talks/2025-umass-r-cafe/slides.html#quarto-file-template",
    "title": "Making your workflow reproducible",
    "section": "Quarto file template",
    "text": "Quarto file template\nUsed for analysis and text"
  },
  {
    "objectID": "talks/2025-umass-r-cafe/slides.html#structure-inside-the-templates-folder",
    "href": "talks/2025-umass-r-cafe/slides.html#structure-inside-the-templates-folder",
    "title": "Making your workflow reproducible",
    "section": "Structure inside the templates folder",
    "text": "Structure inside the templates folder\nNote how this was referenced in the YAML of the Quarto report\n\nSee details on how to create your own reference document for Word output here."
  },
  {
    "objectID": "talks/2025-umass-r-cafe/slides.html#folder-structure-and-naming",
    "href": "talks/2025-umass-r-cafe/slides.html#folder-structure-and-naming",
    "title": "Making your workflow reproducible",
    "section": "Folder structure and naming",
    "text": "Folder structure and naming\nFind something that works for you and stick with it.\n\nWhat I do as a collaborative biostatistician:\n\nStore all project folders on the same drive, backed up by my organization\nEach project gets its own folder\nName the folder as “PIName-brief-project-description”.\n\nFor example, a project with Jane Smith about treatment for metastatic breast cancer might be “Smith-metastatic-breast-trt”\n\nInitialize using {starter}\nAlso add a “data” folder\nProject reports produced by Quarto saved in main project folder as, e.g., “Smith-metastatic-breast-trt-report-2025-10-18” for version control"
  },
  {
    "objectID": "talks/2025-umass-r-cafe/slides.html#rstudio-projects",
    "href": "talks/2025-umass-r-cafe/slides.html#rstudio-projects",
    "title": "Making your workflow reproducible",
    "section": "RStudio projects",
    "text": "RStudio projects\nBenefits of working inside an RStudio project include:\n\nStart a fresh R session every time the project is opened\nThe current working directory is set to the project directory\nPreviously open R scripts are restored at project startup\nOther RStudio settings are restored\nMultiple RStudio sessions can be open at one time, running independently in different RStudio projects"
  },
  {
    "objectID": "talks/2025-umass-r-cafe/slides.html#creating-rstudio-projects",
    "href": "talks/2025-umass-r-cafe/slides.html#creating-rstudio-projects",
    "title": "Making your workflow reproducible",
    "section": "Creating RStudio projects",
    "text": "Creating RStudio projects\n\nAutomatically using the {starter} package\nFile menu in RStudio\nProject menu in RStudio"
  },
  {
    "objectID": "talks/2025-umass-r-cafe/slides.html#rstudio-project-from-the-file-menu",
    "href": "talks/2025-umass-r-cafe/slides.html#rstudio-project-from-the-file-menu",
    "title": "Making your workflow reproducible",
    "section": "RStudio project from the file menu",
    "text": "RStudio project from the file menu"
  },
  {
    "objectID": "talks/2025-umass-r-cafe/slides.html#rstudio-project-from-the-file-menu-1",
    "href": "talks/2025-umass-r-cafe/slides.html#rstudio-project-from-the-file-menu-1",
    "title": "Making your workflow reproducible",
    "section": "RStudio project from the file menu",
    "text": "RStudio project from the file menu"
  },
  {
    "objectID": "talks/2025-umass-r-cafe/slides.html#rstudio-project-from-the-file-menu-2",
    "href": "talks/2025-umass-r-cafe/slides.html#rstudio-project-from-the-file-menu-2",
    "title": "Making your workflow reproducible",
    "section": "RStudio project from the file menu",
    "text": "RStudio project from the file menu"
  },
  {
    "objectID": "talks/2025-umass-r-cafe/slides.html#rstudio-project-from-the-project-menu",
    "href": "talks/2025-umass-r-cafe/slides.html#rstudio-project-from-the-project-menu",
    "title": "Making your workflow reproducible",
    "section": "RStudio project from the project menu",
    "text": "RStudio project from the project menu"
  },
  {
    "objectID": "talks/2025-umass-r-cafe/slides.html#workflow-with-rstudio-project",
    "href": "talks/2025-umass-r-cafe/slides.html#workflow-with-rstudio-project",
    "title": "Making your workflow reproducible",
    "section": "Workflow with RStudio project",
    "text": "Workflow with RStudio project"
  },
  {
    "objectID": "talks/2025-umass-r-cafe/slides.html#the-here-package",
    "href": "talks/2025-umass-r-cafe/slides.html#the-here-package",
    "title": "Making your workflow reproducible",
    "section": "The {here} package",
    "text": "The {here} package\n\n\n\n\n\n“Easy file referencing in project-oriented workflows”"
  },
  {
    "objectID": "talks/2025-umass-r-cafe/slides.html#what-does-it-do",
    "href": "talks/2025-umass-r-cafe/slides.html#what-does-it-do",
    "title": "Making your workflow reproducible",
    "section": "What does it do?",
    "text": "What does it do?\nCreates paths relative to the top-level directory.\n\n# install.packages(\"here\")\n\nhere::here()\n\n[1] \"D:/zabore.github.io\""
  },
  {
    "objectID": "talks/2025-umass-r-cafe/slides.html#how-to-use-it-examples",
    "href": "talks/2025-umass-r-cafe/slides.html#how-to-use-it-examples",
    "title": "Making your workflow reproducible",
    "section": "How to use it: examples",
    "text": "How to use it: examples\nRead in data\n\n# install.packages(\"readr\")\ndf &lt;- readr::read_csv(here::here(\"data\", \"mydata.csv\"))\n\n\nSave files\n\nmyplot &lt;- hist(rnorm(100))\nsave(here::here(\"plots\", \"myhistogram.jpg\"))"
  },
  {
    "objectID": "talks/2025-umass-r-cafe/slides.html#quarto-reports",
    "href": "talks/2025-umass-r-cafe/slides.html#quarto-reports",
    "title": "Making your workflow reproducible",
    "section": "Quarto reports",
    "text": "Quarto reports\n\nStarted using RMarkdown reports, switched to Quarto.\nVery easy to switch and I still use a lot of RMarkdown style programming in my Quarto files.\nNever again:\n\nhardcode a number\nhave separate documents for text and tables\nmanually create tables\nhave difficulty updating results when data change\n\nEasily mix code chunks with text\nReport numbers in-line in a programmatic way"
  },
  {
    "objectID": "talks/2025-umass-r-cafe/slides.html#separate-files-for-data-preparation-and-data-reporting",
    "href": "talks/2025-umass-r-cafe/slides.html#separate-files-for-data-preparation-and-data-reporting",
    "title": "Making your workflow reproducible",
    "section": "Separate files for data preparation and data reporting",
    "text": "Separate files for data preparation and data reporting\nRecall my starter template created two shell documents:\n\nR script where data are cleaned and coded and saved into a .rda file\nQuarto file where clean data are read in, analyses done, results reported"
  },
  {
    "objectID": "talks/2025-umass-r-cafe/slides.html#what-do-i-include",
    "href": "talks/2025-umass-r-cafe/slides.html#what-do-i-include",
    "title": "Making your workflow reproducible",
    "section": "What do I include?",
    "text": "What do I include?\nI write my Quarto reports with four main sections:\n\nNotes/questions: these are notes on things I did in the data cleaning process that I want to call attention to, i.e. how categories were combined, missing data to address, data issues or inconsistencies, etc\nBackground: a brief description of the problem or question being addressed by the project\nMethods: A formal statistical methods section that can be copied and pasted directly into the eventual scientific publication\nResults: Mostly tables and figures with some text interpretation mixed in."
  },
  {
    "objectID": "talks/2025-umass-r-cafe/slides.html#quarto-output-options",
    "href": "talks/2025-umass-r-cafe/slides.html#quarto-output-options",
    "title": "Making your workflow reproducible",
    "section": "Quarto output options",
    "text": "Quarto output options\n\nhtml: probably the most popular, with many customization options\npdf: the trickiest to use, in my opinion, requires a LaTeX installation\nWord: unpopular, but my preference as it makes it easy to copy and paste entire tables and blocks of text from my report into the publication\n\n Note that you can also make slides in Quarto, like these slides, but that is not our focus today"
  },
  {
    "objectID": "talks/2025-umass-r-cafe/slides.html#components-of-a-quarto-file",
    "href": "talks/2025-umass-r-cafe/slides.html#components-of-a-quarto-file",
    "title": "Making your workflow reproducible",
    "section": "Components of a Quarto file",
    "text": "Components of a Quarto file\n\nThe YAML header\nCode chunks\nMarkdown text"
  },
  {
    "objectID": "talks/2025-umass-r-cafe/slides.html#the-yaml-header",
    "href": "talks/2025-umass-r-cafe/slides.html#the-yaml-header",
    "title": "Making your workflow reproducible",
    "section": "The YAML header",
    "text": "The YAML header"
  },
  {
    "objectID": "talks/2025-umass-r-cafe/slides.html#code-chunks",
    "href": "talks/2025-umass-r-cafe/slides.html#code-chunks",
    "title": "Making your workflow reproducible",
    "section": "Code chunks",
    "text": "Code chunks"
  },
  {
    "objectID": "talks/2025-umass-r-cafe/slides.html#markdown-text",
    "href": "talks/2025-umass-r-cafe/slides.html#markdown-text",
    "title": "Making your workflow reproducible",
    "section": "Markdown text",
    "text": "Markdown text"
  },
  {
    "objectID": "talks/2025-umass-r-cafe/slides.html#rendering",
    "href": "talks/2025-umass-r-cafe/slides.html#rendering",
    "title": "Making your workflow reproducible",
    "section": "Rendering",
    "text": "Rendering\n\n\nThis places the output file inside the same folder where the .qmd file is saved, in this case in the code folder\nI always “Save As” to the main project folder with the date of the file creation for version control"
  },
  {
    "objectID": "talks/2025-umass-r-cafe/slides.html#the-renv-package",
    "href": "talks/2025-umass-r-cafe/slides.html#the-renv-package",
    "title": "Making your workflow reproducible",
    "section": "The {renv} package",
    "text": "The {renv} package\n\n\n\n\n\n“create reproducible environments for your R projects”"
  },
  {
    "objectID": "talks/2025-umass-r-cafe/slides.html#initialize-the-project",
    "href": "talks/2025-umass-r-cafe/slides.html#initialize-the-project",
    "title": "Making your workflow reproducible",
    "section": "Initialize the project",
    "text": "Initialize the project\nFirst run renv::init() to initialize a new library. This was done for us with starter::create_project()."
  },
  {
    "objectID": "talks/2025-umass-r-cafe/slides.html#other-renv-functions",
    "href": "talks/2025-umass-r-cafe/slides.html#other-renv-functions",
    "title": "Making your workflow reproducible",
    "section": "Other {renv} functions",
    "text": "Other {renv} functions\n\ninstall() to install packages from CRAN, GitHub, or Bioconductor\nupdate() gets the latest versions of all dependencies\n\nFor collaboration with others:\n\nsnapshot() adds metadata about currently used packages to the lockfile\nrestore() uses metadata from the lockfile to install exactly the same version of every package"
  },
  {
    "objectID": "talks/2025-umass-r-cafe/slides.html#put-it-all-together",
    "href": "talks/2025-umass-r-cafe/slides.html#put-it-all-together",
    "title": "Making your workflow reproducible",
    "section": "Put it all together",
    "text": "Put it all together\nCase study: I am starting a new project with Dr. Jane Smith about the association between radiation treatment and overall survival in women with breast cancer. Dr. Smith has emailed me an Excel dataset to analyze for the project, and we have discussed the analysis plan."
  },
  {
    "objectID": "talks/2025-umass-r-cafe/slides.html#run-startercreate_project",
    "href": "talks/2025-umass-r-cafe/slides.html#run-startercreate_project",
    "title": "Making your workflow reproducible",
    "section": "Run starter::create_project()",
    "text": "Run starter::create_project()\n\nstarter::create_project(\n  path = fs::path(\"G:/StatTeam/zabore/Smith-breast-radiation\"),\n  template = ezfun::ez_analysis_template,\n  open = FALSE\n)\n\n✔ Using \"EZ Analysis Template\" template\n\n\n✔ Writing files \n\n\n✔ Initialising renv project\n\n\n- Lockfile written to \"G:/StatTeam/zabore/Smith-breast-radiation/renv.lock\".\n- renv infrastructure has been generated for project \"G:/StatTeam/zabore/Smith-breast-radiation\".\n\n\nNotes:\n\n“G:/StatTeam/zabore” is my organization’s preferred and backed-up drive on my computer\nA new project folder named “Smith-breast-radiation” will be created and populated"
  },
  {
    "objectID": "talks/2025-umass-r-cafe/slides.html#add-a-data-folder-and-save-the-data-there",
    "href": "talks/2025-umass-r-cafe/slides.html#add-a-data-folder-and-save-the-data-there",
    "title": "Making your workflow reproducible",
    "section": "Add a data folder and save the data there",
    "text": "Add a data folder and save the data there\n\nThe investigator sent me an Excel file, which I save as is\nI also “Save As” a csv, which I’ll import to R for data cleaning"
  },
  {
    "objectID": "talks/2025-umass-r-cafe/slides.html#open-the-rstudio-project",
    "href": "talks/2025-umass-r-cafe/slides.html#open-the-rstudio-project",
    "title": "Making your workflow reproducible",
    "section": "Open the RStudio project",
    "text": "Open the RStudio project\nOnce in the RStudio project:\n\nOpen the two shell files (R script and qmd)\nStart to install needed packages using renv::install()\n\n\nInsert comments on speed and other issues"
  },
  {
    "objectID": "talks/2025-umass-r-cafe/slides.html#read-in-clean-up-and-save-the-data",
    "href": "talks/2025-umass-r-cafe/slides.html#read-in-clean-up-and-save-the-data",
    "title": "Making your workflow reproducible",
    "section": "Read in, clean up, and save the data",
    "text": "Read in, clean up, and save the data\n\nThis is one place where the {here} package will come in handy\n\n\nlibrary(dplyr)\nlibrary(readr)\n\n# Import data ------------------------------------\ndf0 &lt;-\n  read_csv(\n    file = here::here(\"data\", \"breastcancer.csv\")\n  )  |&gt;\n  janitor::clean_names() |&gt;\n  janitor::remove_empty()\n\n# Clean data -------------------------------------\ndf &lt;- \n  df0 |&gt; \n  mutate(\n    # Insert data cleaning steps here\n  ) |&gt;\n  labelled::set_variable_labels(\n    # Insert variable labels here\n  )\n\n# Save the data ----------------------------------\nsave(\n  df,\n  file = here::here(\"data\", \"smith-breast-rt-data.rda\"))\n\nInsert comments on {janitor}"
  },
  {
    "objectID": "talks/2025-umass-r-cafe/slides.html#analyze-and-report-in-quarto",
    "href": "talks/2025-umass-r-cafe/slides.html#analyze-and-report-in-quarto",
    "title": "Making your workflow reproducible",
    "section": "Analyze and report in Quarto",
    "text": "Analyze and report in Quarto"
  },
  {
    "objectID": "talks/2025-umass-r-cafe/slides.html#view-the-resulting-report",
    "href": "talks/2025-umass-r-cafe/slides.html#view-the-resulting-report",
    "title": "Making your workflow reproducible",
    "section": "View the resulting report",
    "text": "View the resulting report"
  },
  {
    "objectID": "talks/2025-umass-r-cafe/slides.html#save-the-report-with-a-new-name",
    "href": "talks/2025-umass-r-cafe/slides.html#save-the-report-with-a-new-name",
    "title": "Making your workflow reproducible",
    "section": "Save the report with a new name",
    "text": "Save the report with a new name"
  },
  {
    "objectID": "talks/2025-umass-r-cafe/slides.html#connect-with-me",
    "href": "talks/2025-umass-r-cafe/slides.html#connect-with-me",
    "title": "Making your workflow reproducible",
    "section": "Connect with me",
    "text": "Connect with me\n\n\n zabore2@ccf.org\n https://www.emilyzabor.com/\n https://github.com/zabore\n https://www.linkedin.com/in/emily-zabor-59b902b7/\n https://bsky.app/profile/zabore.bsky.social/"
  },
  {
    "objectID": "talks/2024-rladies-philly/index.html",
    "href": "talks/2024-rladies-philly/index.html",
    "title": "R-Ladies Philly: Introduction to Survival Analysis in R",
    "section": "",
    "text": "Full Screen"
  },
  {
    "objectID": "software.html",
    "href": "software.html",
    "title": "Software",
    "section": "",
    "text": "An R package of functions to design clinical trials with sequential Bayesian predictive probability monitoring for futility. Currently functionality is available for one-arm and two-arm clinical trials, and functionality for basket trials is under development.\n\n\n\n\n\n\n\n\n\nDetails at http://www.emilyzabor.com/ppseq/"
  },
  {
    "objectID": "software.html#ppseq",
    "href": "software.html#ppseq",
    "title": "Software",
    "section": "",
    "text": "An R package of functions to design clinical trials with sequential Bayesian predictive probability monitoring for futility. Currently functionality is available for one-arm and two-arm clinical trials, and functionality for basket trials is under development.\n\n\n\n\n\n\n\n\n\nDetails at http://www.emilyzabor.com/ppseq/"
  },
  {
    "objectID": "software.html#riskclustr",
    "href": "software.html#riskclustr",
    "title": "Software",
    "section": "riskclustr",
    "text": "riskclustr\nAn R package of functions for the study of etiologic heterogeneity.\nDetails at https://www.emilyzabor.com/riskclustr/"
  },
  {
    "objectID": "software.html#condsurv",
    "href": "software.html#condsurv",
    "title": "Software",
    "section": "condsurv",
    "text": "condsurv\nA package for conditional survival analysis.\n\n\n\n\n\n\n\n\n\nDetails at https://www.emilyzabor.com/condsurv/"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Emily C. Zabor",
    "section": "",
    "text": "I am an Associate Staff Biostatistician at the Cleveland Clinic in the Department of Quantitative Health Sciences, with a joint appointment in the Taussig Cancer Institute. I also hold an academic appointment as Associate Professor of Medicine at the Cleveland Clinic Lerner College of Medicine of Case Western Reserve University.\nMy research interests are in early phase clinical trial design, statistical methods for observational studies, prediction models, and survival analysis. I am an enthusiastic R user.\nI earned an MS degree in biostatistics from The University of Minnesota and a DrPH degree in biostatistics from Columbia University.\nPlease see my CV for details of my academic work."
  },
  {
    "objectID": "survival-analysis-in-r.html",
    "href": "survival-analysis-in-r.html",
    "title": "Survival analysis in R",
    "section": "",
    "text": "This tutorial provides an introduction to survival analysis, and to conducting a survival analysis in R. This tutorial was originally presented at the Memorial Sloan Kettering Cancer Center R-Presenters series on August 30, 2018. It was then modified for a more extensive training at Memorial Sloan Kettering Cancer Center in March, 2019. Updates, sometimes significant, are made when new functionality becomes available in R. This tutorial reflects my own opinions about the best functionality available in R for survival analysis.\nLast updated: 2025-10-21\nFirst, install and load some packages that will be used throughout.\n# Install packages if needed\n# install.packages(c(\"knitr\", \"dplyr\", \"survival\", \"ggplot2\", \"here\", \"tibble\"))\nlibrary(knitr)\nlibrary(dplyr)\nlibrary(survival)\nlibrary(ggplot2)\nlibrary(tibble)\n\n# devtools::install_github(\"zabore/ezfun\")\nezfun::set_ccf_palette(\"contrast\")"
  },
  {
    "objectID": "survival-analysis-in-r.html#part-1-introduction-to-survival-analysis",
    "href": "survival-analysis-in-r.html#part-1-introduction-to-survival-analysis",
    "title": "Survival analysis in R",
    "section": "Part 1: Introduction to Survival Analysis",
    "text": "Part 1: Introduction to Survival Analysis\nThis presentation will cover some basics of survival analysis, and the following series of tutorial papers can be helpful for additional reading:\n\nClark, T., Bradburn, M., Love, S., & Altman, D. (2003). Survival analysis part I: Basic concepts and first analyses. 232-238. ISSN 0007-0920.\n\n\nM J Bradburn, T G Clark, S B Love, & D G Altman. (2003). Survival Analysis Part II: Multivariate data analysis – an introduction to concepts and methods. British Journal of Cancer, 89(3), 431-436.\n\n\nBradburn, M., Clark, T., Love, S., & Altman, D. (2003). Survival analysis Part III: Multivariate data analysis – choosing a model and assessing its adequacy and fit. 89(4), 605-11.\n\n\nClark, T., Bradburn, M., Love, S., & Altman, D. (2003). Survival analysis part IV: Further concepts and methods in survival analysis. 781-786. ISSN 0007-0920."
  },
  {
    "objectID": "survival-analysis-in-r.html#the-basics",
    "href": "survival-analysis-in-r.html#the-basics",
    "title": "Survival analysis in R",
    "section": "The basics",
    "text": "The basics\nSurvival data are time-to-event data that consist of a distinct start time and end time.\nExamples from cancer:\n\nTime from surgery to death\nTime from start of treatment to progression\nTime from response to recurrence\n\nTime-to-event data are common in many other fields. Some other examples include:\n\nTime from HIV infection to development of AIDS\nTime to heart attack\nTime to onset of substance abuse\nTime to initiation of sexual activity\nTime to machine malfunction\n\nBecause time-to-event data are common in many fields, it also goes by names besides survival analysis including:\n\nReliability analysis\nDuration analysis\nEvent history analysis\nTime-to-event analysis\n\nA key feature of survival data is censoring.\n\n\n\n\n\n\n\n\n\n\nRICH JT, NEELY JG, PANIELLO RC, VOELKER CCJ, NUSSENBAUM B, WANG EW. A PRACTICAL GUIDE TO UNDERSTANDING KAPLAN-MEIER CURVES. Otolaryngology head and neck surgery: official journal of American Academy of Otolaryngology Head and Neck Surgery. 2010;143(3):331-336. doi:10.1016/j.otohns.2010.05.007.\n\nA subject may be censored due to:\n\nLoss to follow-up\nWithdrawal from study\nNo event by end of fixed study period\n\nSpecifically these are examples of right censoring. Left censoring and interval censoring are also possible, and methods exist to analyze these types of data, but this tutorial will be focus on right censoring.\nTo illustrate the impact of censoring, suppose we have the following data:\n\n\n\n\n\n\n\n\n\nHow would we compute the proportion who are event-free at 10 years?\n\nSubjects 6 and 7 were event-free at 10 years.\nSubjects 2, 9, and 10 had the event before 10 years.\nSubjects 1, 3, 4, 5, and 8 were censored before 10 years, so we don’t know whether they had the event or not at 10 years. But we know something about them - that they were each followed for a certain amount of time without the event of interest prior to being censored.\n\nSurvival analysis techniques provide a way to appropriately account for censored patients in the analysis.\nOther reasons specialized analysis techniques are needed:\n\nThe distribution of follow-up times is skewed, and may differ between censored patients and those with events\nFollow-up times are always positive\n\nExample of the distribution of follow-up times according to event status:\n\n\n\n\n\n\n\n\n\nTo analyze survival data, we need to know the observed time \\(Y_i\\) and the event indicator \\(\\delta_i\\). For subject \\(i\\):\n\nObserved time \\(Y_i = \\min(T_i, C_i)\\) where \\(T_i\\) = event time and \\(C_i\\) = censoring time\nEvent indicator \\(\\delta_i\\) = 1 if event observed (i.e. \\(T_i \\leq C_i\\)), = 0 if censored (i.e. \\(T_i &gt; C_i\\))\n\nThe probability that a subject will survive beyond any given specified time\n\\[S(t) = Pr(T&gt;t) = 1 - F(t)\\]\n\\(S(t)\\): survival function \\(F(t) = Pr(T \\leq t)\\): cumulative distribution function\nIn theory the survival function is smooth; in practice we observe events on a discrete time scale.\nThe survival probability at a certain time, \\(S(t)\\), is a conditional probability of surviving beyond that time, given that an individual has survived just prior to that time. The survival probability can be estimated as the number of patients who are alive without loss to follow-up at that time, divided by the number of patients who were alive just prior to that time.\nThe Kaplan-Meier estimate of survival probability at a given time is the product of these conditional probabilities up until that given time.\nAt time 0, the survival probability is 1, i.e. \\(S(t_0) = 1\\)."
  },
  {
    "objectID": "survival-analysis-in-r.html#packages",
    "href": "survival-analysis-in-r.html#packages",
    "title": "Survival analysis in R",
    "section": "Packages",
    "text": "Packages\nIn this section, we will use the following packages:\n\n# install.packages(c(\"lubridate\", \"ggsurvfit\", \"gtsummary\", \"tidycmprsk\"))\nlibrary(lubridate)\nlibrary(ggsurvfit)\nlibrary(gtsummary)\nlibrary(tidycmprsk)\n\n# devtools::install_github(\"zabore/condsurv\")\nlibrary(condsurv)"
  },
  {
    "objectID": "survival-analysis-in-r.html#the-lung-dataset",
    "href": "survival-analysis-in-r.html#the-lung-dataset",
    "title": "Survival analysis in R",
    "section": "The lung dataset",
    "text": "The lung dataset\nThroughout this section, we will use the lung dataset from the {survival} package as example data. The data contain subjects with advanced lung cancer from the North Central Cancer Treatment Group. We will focus on the following variables throughout this tutorial:\n\ntime: Observed survival time in days\nstatus: censoring status 1=censored, 2=dead\nsex: 1=Male, 2=Female\n\nNote that the status is coded in a non-standard way in this dataset. Typically you will see 1=event, 0=censored. Let’s recode it to avoid confusion:\n\nlung &lt;- \n  lung |&gt; \n  mutate(\n    status = recode(status, `1` = 0, `2` = 1)\n  )\n\nNow we have:\n\ntime: Observed survival time in days\nstatus: censoring status 0=censored, 1=dead\nsex: 1=Male, 2=Female\n\nHere are the first 6 observations:\n\nhead(lung[, c(\"time\", \"status\", \"sex\")])\n\n  time status sex\n1  306      1   1\n2  455      1   1\n3 1010      0   1\n4  210      1   1\n5  883      1   1\n6 1022      0   1\n\n\nNote: the Surv() function in the {survival} package accepts by default TRUE/FALSE, where TRUE is event and FALSE is censored; 1/0 where 1 is event and 0 is censored; or 2/1 where 2 is event and 1 is censored. Please take care to ensure the event indicator is properly formatted."
  },
  {
    "objectID": "survival-analysis-in-r.html#calculating-survival-times",
    "href": "survival-analysis-in-r.html#calculating-survival-times",
    "title": "Survival analysis in R",
    "section": "Calculating survival times",
    "text": "Calculating survival times\nData will often come with start and end dates rather than pre-calculated survival times. The first step is to make sure these are formatted as dates in R.\nLet’s create a small example dataset with variables sx_date for surgery date and last_fup_date for the last follow-up date:\n\ndate_ex &lt;- \n  tibble(\n    sx_date = c(\"2007-06-22\", \"2004-02-13\", \"2010-10-27\"), \n    last_fup_date = c(\"2017-04-15\", \"2018-07-04\", \"2016-10-31\")\n    )\n\ndate_ex\n\n# A tibble: 3 × 2\n  sx_date    last_fup_date\n  &lt;chr&gt;      &lt;chr&gt;        \n1 2007-06-22 2017-04-15   \n2 2004-02-13 2018-07-04   \n3 2010-10-27 2016-10-31   \n\n\nWe see these are both character variables, but we need them to be formatted as dates.\nWe will use the {lubridate} package to work with dates. In this case, we need to use the ymd() function to change the format, since the dates are currently in the character format where the year comes first, followed by the month, and followed by the day.\n\ndate_ex &lt;-\n  date_ex |&gt; \n  mutate(\n    sx_date = ymd(sx_date), \n    last_fup_date = ymd(last_fup_date)\n    )\n\ndate_ex\n\n# A tibble: 3 × 2\n  sx_date    last_fup_date\n  &lt;date&gt;     &lt;date&gt;       \n1 2007-06-22 2017-04-15   \n2 2004-02-13 2018-07-04   \n3 2010-10-27 2016-10-31   \n\n\nNow we see that the two dates are formatted as date rather than as character. Access the help page with ?ymd to see all date format options.\nNow that the dates are formatted, we need to calculate the difference between start and end dates in some units, usually months or years. Using the {lubridate} package, the operator %--% designates a time interval, which is then converted to the number of elapsed seconds using as.duration() and finally converted to years by dividing by dyears(1), which gives the number of seconds in a year.\n\ndate_ex &lt;-\n  date_ex |&gt; \n  mutate(\n    os_yrs = as.duration(sx_date %--% last_fup_date) / dyears(1)\n    )\n\ndate_ex\n\n# A tibble: 3 × 3\n  sx_date    last_fup_date os_yrs\n  &lt;date&gt;     &lt;date&gt;         &lt;dbl&gt;\n1 2007-06-22 2017-04-15      9.82\n2 2004-02-13 2018-07-04     14.4 \n3 2010-10-27 2016-10-31      6.01\n\n\nNow we have our observed time for use in survival analysis.\nNote: we need to load the {lubridate} package using a call to library in order to be able to access the special operators (similar to situation with pipes - i.e. we can’t use lubridate::ymd() and then expect to use the special operators)."
  },
  {
    "objectID": "survival-analysis-in-r.html#creating-survival-objects-and-curves",
    "href": "survival-analysis-in-r.html#creating-survival-objects-and-curves",
    "title": "Survival analysis in R",
    "section": "Creating survival objects and curves",
    "text": "Creating survival objects and curves\nThe Kaplan-Meier method is the most common way to estimate survival times and probabilities. It is a non-parametric approach that results in a step function, where there is a step down each time an event occurs.\nThe Surv() function from the {survival} package creates a survival object for use as the response in a model formula. There will be one entry for each subject that is the survival time, which is followed by a + if the subject was censored. Let’s look at the first 10 observations:\n\nSurv(lung$time, lung$status)[1:10]\n\n [1]  306   455  1010+  210   883  1022+  310   361   218   166 \n\n\nWe see that subject 1 had an event at time 306 days, subject 2 had an event at time 455 days, subject 3 was censored at time 1010 days, etc.\nThe survfit() function creates survival curves using the Kaplan-Meier method based on a formula. Let’s generate the overall survival curve for the entire cohort, assign it to object s1, and look at the structure using str():\n\ns1 &lt;- survfit(Surv(time, status) ~ 1, data = lung)\nstr(s1)\n\nList of 17\n $ n        : int 228\n $ time     : num [1:186] 5 11 12 13 15 26 30 31 53 54 ...\n $ n.risk   : num [1:186] 228 227 224 223 221 220 219 218 217 215 ...\n $ n.event  : num [1:186] 1 3 1 2 1 1 1 1 2 1 ...\n $ n.censor : num [1:186] 0 0 0 0 0 0 0 0 0 0 ...\n $ surv     : num [1:186] 0.996 0.982 0.978 0.969 0.965 ...\n $ std.err  : num [1:186] 0.0044 0.00885 0.00992 0.01179 0.01263 ...\n $ cumhaz   : num [1:186] 0.00439 0.0176 0.02207 0.03103 0.03556 ...\n $ std.chaz : num [1:186] 0.00439 0.0088 0.00987 0.01173 0.01257 ...\n $ type     : chr \"right\"\n $ logse    : logi TRUE\n $ conf.int : num 0.95\n $ conf.type: chr \"log\"\n $ lower    : num [1:186] 0.987 0.966 0.959 0.947 0.941 ...\n $ upper    : num [1:186] 1 1 0.997 0.992 0.989 ...\n $ t0       : num 0\n $ call     : language survfit(formula = Surv(time, status) ~ 1, data = lung)\n - attr(*, \"class\")= chr \"survfit\"\n\n\nSome key components of this survfit object that will be used to create survival curves include:\n\ntime: the timepoints at which the curve has a step, i.e. at least one event occurred\nsurv: the estimate of survival at the corresponding time"
  },
  {
    "objectID": "survival-analysis-in-r.html#kaplan-meier-plots",
    "href": "survival-analysis-in-r.html#kaplan-meier-plots",
    "title": "Survival analysis in R",
    "section": "Kaplan-Meier plots",
    "text": "Kaplan-Meier plots\nWe will use the {ggsurvfit} package to generate Kaplan-Meier plots. This package aims to ease plotting of time-to-event endpoints using the power of the {ggplot2} package. See http://www.danieldsjoberg.com/ggsurvfit/index.html for details.\nNote: alternatively, survival plots can be created using base R or the {survminer} package.\nThe {ggsurvfit} package works best if you create the survfit object using the included ggsurvfit::survfit2() function, which uses the same syntax to what we saw previously with survival::survfit(). The ggsurvfit::survfit2() tracks the environment from the function call, which allows the plot to have better default values for labeling and p-value reporting.\n\nsurvfit2(Surv(time, status) ~ 1, data = lung) |&gt; \n  ggsurvfit() +\n  labs(\n    x = \"Days\",\n    y = \"Overall survival probability\"\n  )\n\n\n\n\n\n\n\n\nThe default plot in ggsurvfit() shows the step function only. We can add the confidence interval using add_confidence_interval():\n\nsurvfit2(Surv(time, status) ~ 1, data = lung) |&gt; \n  ggsurvfit() +\n  labs(\n    x = \"Days\",\n    y = \"Overall survival probability\"\n  ) + \n  add_confidence_interval()\n\n\n\n\n\n\n\n\nTypically we will also want to see the numbers at risk in a table below the x-axis. We can add this using add_risktable():\n\nsurvfit2(Surv(time, status) ~ 1, data = lung) |&gt; \n  ggsurvfit() +\n  labs(\n    x = \"Days\",\n    y = \"Overall survival probability\"\n    ) + \n  add_confidence_interval() +\n  add_risktable()\n\n\n\n\n\n\n\n\nPlots can be customized using many standard {ggplot2} options."
  },
  {
    "objectID": "survival-analysis-in-r.html#estimating-x-year-survival",
    "href": "survival-analysis-in-r.html#estimating-x-year-survival",
    "title": "Survival analysis in R",
    "section": "Estimating \\(x\\)-year survival",
    "text": "Estimating \\(x\\)-year survival\nOne quantity often of interest in a survival analysis is the probability of surviving beyond a certain number of years, \\(x\\).\nFor example, to estimate the probability of surviving to \\(1\\) year, use summary with the times argument (Note: the time variable in the lung data is actually in days, so we need to use times = 365.25)\n\nsummary(survfit(Surv(time, status) ~ 1, data = lung), times = 365.25)\n\nCall: survfit(formula = Surv(time, status) ~ 1, data = lung)\n\n time n.risk n.event survival std.err lower 95% CI upper 95% CI\n  365     65     121    0.409  0.0358        0.345        0.486\n\n\nWe find that the \\(1\\)-year probability of survival in this study is 41%.\nThe associated lower and upper bounds of the 95% confidence interval are also displayed.\nThe \\(1\\)-year survival probability is the point on the y-axis that corresponds to \\(1\\) year on the x-axis for the survival curve.\n\n\n\n\n\n\n\n\n\nWhat happens if you use a “naive” estimate? Here “naive” means that the patients who were censored prior to 1-year are considered event-free and included in the denominator.\n121 of the 228 patients in the lung data died by \\(1\\) year so the “naive” estimate is calculated as:\n\\[\\Big(1 - \\frac{121}{228}\\Big) \\times 100 = 47\\%\\] You get an incorrect estimate of the \\(1\\)-year probability of survival when you ignore the fact that 42 patients were censored before \\(1\\) year.\nRecall the correct estimate of the \\(1\\)-year probability of survival, accounting for censoring using the Kaplan-Meier method, was 41%.\nIgnoring censoring leads to an overestimate of the overall survival probability. Imagine two studies, each with 228 subjects. There are 165 deaths in each study. Censoring is ignored in one (blue line), censoring is accounted for in the other (yellow line). The censored subjects only contribute information for a portion of the follow-up time, and then fall out of the risk set, thus pulling down the cumulative probability of survival. Ignoring censoring erroneously treats patients who are censored as part of the risk set for the entire follow-up period.\n\n\n\n\n\n\n\n\n\nWe can produce nice tables of \\(x\\)-time survival probability estimates using the tbl_survfit() function from the {gtsummary} package:\n\nsurvfit(Surv(time, status) ~ 1, data = lung) |&gt; \n  tbl_survfit(\n    times = 365.25,\n    label_header = \"**1-year survival (95% CI)**\"\n  )\n\n\n\n\n\n\n\nCharacteristic\n1-year survival (95% CI)\n\n\n\n\nOverall\n41% (34%, 49%)"
  },
  {
    "objectID": "survival-analysis-in-r.html#estimating-median-survival-time",
    "href": "survival-analysis-in-r.html#estimating-median-survival-time",
    "title": "Survival analysis in R",
    "section": "Estimating median survival time",
    "text": "Estimating median survival time\nAnother quantity often of interest in a survival analysis is the average survival time, which we quantify using the median. Survival times are not expected to be normally distributed so the mean is not an appropriate summary.\nWe can obtain the median survival directly from the survfit object:\n\nsurvfit(Surv(time, status) ~ 1, data = lung)\n\nCall: survfit(formula = Surv(time, status) ~ 1, data = lung)\n\n       n events median 0.95LCL 0.95UCL\n[1,] 228    165    310     285     363\n\n\nWe see the median survival time is 310 days The lower and upper bounds of the 95% confidence interval are also displayed.\nMedian survival is the time corresponding to a survival probability of \\(0.5\\):\n\n\n\n\n\n\n\n\n\nWhat happens if you use a “naive” estimate? Here “naive” means that you exclude the censored patients from the calculation entirely to estimate median survival time among the patients who have had the event.\nSummarize the median survival time among the 165 patients who died:\n\nlung |&gt; \n  filter(status == 1) |&gt; \n  summarize(median_surv = median(time))\n\n  median_surv\n1         226\n\n\nYou get an incorrect estimate of median survival time of 226 days when you ignore the fact that censored patients also contribute follow-up time.\nRecall the correct estimate of median survival time is 310 days.\nIgnoring censoring will lead to an underestimate of median survival time because the follow-up time that censored patients contribute is excluded (blue line). The true survival curve accounting for censoring in the lung data is shown in yellow for comparison.\n\n\n\n\n\n\n\n\n\nWe can produce nice tables of median survival time estimates using the tbl_survfit() function from the {gtsummary} package:\n\nsurvfit(Surv(time, status) ~ 1, data = lung) |&gt; \n  tbl_survfit(\n    probs = 0.5,\n    label_header = \"**Median survival (95% CI)**\"\n  )\n\n\n\n\n\n\n\nCharacteristic\nMedian survival (95% CI)\n\n\n\n\nOverall\n310 (285, 363)"
  },
  {
    "objectID": "survival-analysis-in-r.html#comparing-survival-times-between-groups",
    "href": "survival-analysis-in-r.html#comparing-survival-times-between-groups",
    "title": "Survival analysis in R",
    "section": "Comparing survival times between groups",
    "text": "Comparing survival times between groups\nWe can conduct between-group significance tests using a log-rank test. The log-rank test equally weights observations over the entire follow-up time and is the most common way to compare survival times between groups. There are versions that more heavily weight the early or late follow-up that could be more appropriate depending on the research question (see ?survdiff for different test options).\nWe get the log-rank p-value using the survdiff function. For example, we can test whether there was a difference in survival time according to sex in the lung data:\n\nsurvdiff(Surv(time, status) ~ sex, data = lung)\n\nCall:\nsurvdiff(formula = Surv(time, status) ~ sex, data = lung)\n\n        N Observed Expected (O-E)^2/E (O-E)^2/V\nsex=1 138      112     91.6      4.55      10.3\nsex=2  90       53     73.4      5.68      10.3\n\n Chisq= 10.3  on 1 degrees of freedom, p= 0.001 \n\n\nWe see that there was a significant difference in overall survival according to sex in the lung data, with a p-value of p = 0.001."
  },
  {
    "objectID": "survival-analysis-in-r.html#the-cox-regression-model",
    "href": "survival-analysis-in-r.html#the-cox-regression-model",
    "title": "Survival analysis in R",
    "section": "The Cox regression model",
    "text": "The Cox regression model\nWe may want to quantify an effect size for a single variable, or include more than one variable into a regression model to account for the effects of multiple variables.\nThe Cox regression model is a semi-parametric model that can be used to fit univariable and multivariable regression models that have survival outcomes.\n\\[h(t|X_i) = h_0(t) \\exp(\\beta_1 X_{i1} + \\cdots + \\beta_p X_{ip})\\]\n\\(h(t)\\): hazard, or the instantaneous rate at which events occur \\(h_0(t)\\): underlying baseline hazard\nSome key assumptions of the model:\n\nnon-informative censoring\nproportional hazards\n\nNote: parametric regression models for survival outcomes are also available, but they won’t be addressed in this tutorial\nWe can fit regression models for survival data using the coxph() function from the {survival} package, which takes a Surv() object on the left hand side and has standard syntax for regression formulas in R on the right hand side.\n\ncoxph(Surv(time, status) ~ sex, data = lung)\n\nCall:\ncoxph(formula = Surv(time, status) ~ sex, data = lung)\n\n       coef exp(coef) se(coef)      z       p\nsex -0.5310    0.5880   0.1672 -3.176 0.00149\n\nLikelihood ratio test=10.63  on 1 df, p=0.001111\nn= 228, number of events= 165 \n\n\nWe can obtain tables of results using the tbl_regression() function from the {gtsummary} package, with the option to exponentiate set to TRUE to return the hazard ratio rather than the log hazard ratio:\n\ncoxph(Surv(time, status) ~ sex, data = lung) |&gt; \n  tbl_regression(exp = TRUE) \n\n\n\n\n\n\n\nCharacteristic\nHR\n95% CI\np-value\n\n\n\n\nsex\n0.59\n0.42, 0.82\n0.001\n\n\n\nAbbreviations: CI = Confidence Interval, HR = Hazard Ratio\n\n\n\n\n\n\n\n\n\nThe quantity of interest from a Cox regression model is a hazard ratio (HR). The HR represents the ratio of hazards between two groups at any particular point in time. The HR is interpreted as the instantaneous rate of occurrence of the event of interest in those who are still at risk for the event. It is not a risk, though it is commonly mis-interpreted as such. If you have a regression parameter \\(\\beta\\), then HR = \\(\\exp(\\beta)\\).\nA HR &lt; 1 indicates reduced hazard of death whereas a HR &gt; 1 indicates an increased hazard of death.\nSo the HR = 0.59 implies that 0.59 times as many females are dying as males, at any given time. Stated differently, females have a significantly lower hazard of death than males in these data."
  },
  {
    "objectID": "survival-analysis-in-r.html#the-bmt-dataset",
    "href": "survival-analysis-in-r.html#the-bmt-dataset",
    "title": "Survival analysis in R",
    "section": "The BMT dataset",
    "text": "The BMT dataset\nThroughout this section we will use the BMT dataset from {SemiCompRisks} package as an example dataset. The data consist of 137 bone marrow transplant patients. Variables of interest include:\n\nT1 time (in days) to death or last follow-up\ndelta1 death indicator; 1=Dead, 0=Alive\nTA time (in days) to acute graft-versus-host disease\ndeltaA acute graft-versus-host disease indicator; 1-Developed acute graft-versus-host disease, 0-Never developed acute graft-versus-host disease\n\nFirst, load the data for use in examples throughout:\n\n# install.packages(\"SemiCompRisks\")\ndata(BMT, package = \"SemiCompRisks\")\n\nHere are the first 6 observations:\n\nhead(BMT[, c(\"T1\", \"delta1\", \"TA\", \"deltaA\")])\n\n    T1 delta1   TA deltaA\n1 2081      0   67      1\n2 1602      0 1602      0\n3 1496      0 1496      0\n4 1462      0   70      1\n5 1433      0 1433      0\n6 1377      0 1377      0"
  },
  {
    "objectID": "survival-analysis-in-r.html#landmark-approach",
    "href": "survival-analysis-in-r.html#landmark-approach",
    "title": "Survival analysis in R",
    "section": "Landmark approach",
    "text": "Landmark approach\n\nSelect a fixed time after baseline as your landmark time. Note: this should be done based on clinical information, prior to data inspection\nSubset population for those followed at least until landmark time. Note: always report the number excluded due to the event of interest or censoring prior to the landmark time.\nCalculate follow-up from landmark time and apply traditional log-rank tests or Cox regression.\n\nIn the BMT data, interest is in the association between acute graft versus host disease (aGVHD) and survival. But aGVHD is assessed after the transplant, which is our baseline, or start of follow-up, time.\nStep 1 Select landmark time\nTypically aGVHD occurs within the first 90 days following transplant, so we use a 90-day landmark.\nStep 2 Subset population for those followed at least until landmark time\n\nlm_dat &lt;- \n  BMT |&gt; \n  filter(T1 &gt;= 90) \n\nWe exclude 15 patients who were not followed until the landmark time of 90 days.\nNote: All 15 excluded patients died before the 90 day landmark.\nStep 3 Calculate follow-up time from landmark and apply traditional methods.\n\nlm_dat &lt;- \n  lm_dat |&gt; \n  mutate(\n    lm_T1 = T1 - 90\n    )\n\n\nsurvfit2(Surv(lm_T1, delta1) ~ deltaA, data = lm_dat) |&gt; \n  ggsurvfit() +\n  labs(\n    x = \"Days from 90-day landmark\",\n    y = \"Overall survival probability\"\n  ) +\n  add_risktable()\n\n\n\n\n\n\n\n\nIn Cox regression you can use the subset option in coxph to exclude those patients who were not followed through the landmark time, and we can view the results using the tbl_regression() function from the {gtsummary} package:\n\ncoxph(\n  Surv(T1, delta1) ~ deltaA, \n  subset = T1 &gt;= 90, \n  data = BMT\n  ) |&gt; \n  tbl_regression(exp = TRUE)\n\n\n\n\n\n\n\nCharacteristic\nHR\n95% CI\np-value\n\n\n\n\ndeltaA\n1.08\n0.57, 2.07\n0.8\n\n\n\nAbbreviations: CI = Confidence Interval, HR = Hazard Ratio"
  },
  {
    "objectID": "survival-analysis-in-r.html#time-dependent-covariate-approach",
    "href": "survival-analysis-in-r.html#time-dependent-covariate-approach",
    "title": "Survival analysis in R",
    "section": "Time-dependent covariate approach",
    "text": "Time-dependent covariate approach\nAn alternative to a landmark analysis is incorporation of a time-dependent covariate. This may be more appropriate than landmark analysis when:\n\nthe value of a covariate is changing over time\nthere is not an obvious landmark time\nuse of a landmark would lead to many exclusions\n\nAnalysis of time-dependent covariates requires setup of a special dataset, in a format known as counting process format. See the detailed paper on this by the author of the {survival} package Using Time Dependent Covariates and Time Dependent Coefficients in the Cox Model.\nThere was no ID variable in the BMT data, which is needed to create the special dataset, so create an ID variable called my_id:\n\nBMT &lt;- rowid_to_column(BMT, \"my_id\")\n\nUse the tmerge function with the event and tdc function options to create the special dataset.\n\ntmerge() creates a long dataset with multiple time intervals for the different covariate values for each patient\nevent() creates the new event indicator to go with the newly created time intervals\ntdc() creates the time-dependent covariate indicator to go with the newly created time intervals\n\n\ntd_dat &lt;- \n  tmerge(\n    data1 = BMT |&gt; select(my_id, T1, delta1), \n    data2 = BMT |&gt; select(my_id, T1, delta1, TA, deltaA), \n    id = my_id, \n    death = event(T1, delta1),\n    agvhd = tdc(TA)\n    )\n\nTo see what this does, let’s look at the data for the first 5 individual patients. The variables of interest in the original data looked like:\n\n\n  my_id   T1 delta1   TA deltaA\n1     1 2081      0   67      1\n2     2 1602      0 1602      0\n3     3 1496      0 1496      0\n4     4 1462      0   70      1\n5     5 1433      0 1433      0\n\n\nThe new dataset for these same patients looks like:\n\n\n  my_id   T1 delta1 tstart tstop death agvhd\n1     1 2081      0      0    67     0     0\n2     1 2081      0     67  2081     0     1\n3     2 1602      0      0  1602     0     0\n4     3 1496      0      0  1496     0     0\n5     4 1462      0      0    70     0     0\n6     4 1462      0     70  1462     0     1\n7     5 1433      0      0  1433     0     0\n\n\nWe see that patients 1 and 4 now have multiple rows of data because they both developed aGVHD at some point in time after baseline.\nNow we can analyze this time-dependent covariate as usual using Cox regression with coxph and an alteration to our use of Surv to include arguments to both time and time2:\n\ncoxph(\n  Surv(time = tstart, time2 = tstop, event = death) ~ agvhd, \n  data = td_dat\n  ) |&gt; \n  tbl_regression(exp = TRUE)\n\n\n\n\n\n\n\nCharacteristic\nHR\n95% CI\np-value\n\n\n\n\nagvhd\n1.40\n0.81, 2.43\n0.2\n\n\n\nAbbreviations: CI = Confidence Interval, HR = Hazard Ratio\n\n\n\n\n\n\n\n\n\nWe find that acute graft versus host disease is not significantly associated with death using either landmark analysis or a time-dependent covariate.\nOften one will want to use landmark analysis for visualization of a single covariate, and Cox regression with a time-dependent covariate for univariable and multivariable modeling."
  },
  {
    "objectID": "survival-analysis-in-r.html#the-melanoma-dataset",
    "href": "survival-analysis-in-r.html#the-melanoma-dataset",
    "title": "Survival analysis in R",
    "section": "The Melanoma dataset",
    "text": "The Melanoma dataset\nWe will use the Melanoma data from the {MASS} package to illustrate these concepts. It contains variables:\n\ntime survival time in days, possibly censored.\nstatus 1 died from melanoma, 2 alive, 3 dead from other causes.\nsex 1 = male, 0 = female.\nage age in years.\nyear of operation.\nthickness tumor thickness in mm.\nulcer 1 = presence, 0 = absence.\n\n\n# install.packages(\"MASS\")\ndata(Melanoma, package = \"MASS\")\n\nThe status variable in these data are coded in a non-standard way. Let’s recode to avoid confusion:\n\nMelanoma &lt;- \n  Melanoma |&gt; \n  mutate(\n    status = as.factor(recode(status, `2` = 0, `1` = 1, `3` = 2))\n  )\n\nNow we have:\n\nstatus 0=alive, 1=died from melanoma, 2=dead from other causes.\n\nHere are the first 6 patients:\n\nhead(Melanoma)\n\n  time status sex age year thickness ulcer\n1   10      2   1  76 1972      6.76     1\n2   30      2   1  56 1968      0.65     0\n3   35      0   1  41 1977      1.34     0\n4   99      2   0  71 1968      2.90     0\n5  185      1   1  52 1965     12.08     1\n6  204      1   1  28 1971      4.84     1"
  },
  {
    "objectID": "survival-analysis-in-r.html#cumulative-incidence-for-competing-risks",
    "href": "survival-analysis-in-r.html#cumulative-incidence-for-competing-risks",
    "title": "Survival analysis in R",
    "section": "Cumulative incidence for competing risks",
    "text": "Cumulative incidence for competing risks\nA non-parametric estimate of the cumulative incidence of the event of interest. At any point in time, the sum of the cumulative incidence of each event is equal to the total cumulative incidence of any event (not true in the cause-specific setting). Gray’s test is a modified Chi-squared test used to compare 2 or more groups.\nEstimate the cumulative incidence in the context of competing risks using the cuminc function from the {tidycmprsk} package. By default this requires the status to be a factor variable with censored patients coded as 0.\n\ncuminc(Surv(time, status) ~ 1, data = Melanoma)\n\ntime    n.risk   estimate   std.error   95% CI          \n1,000   171      0.127      0.023       0.086, 0.177    \n2,000   103      0.230      0.030       0.174, 0.291    \n3,000   54       0.310      0.037       0.239, 0.383    \n4,000   13       0.339      0.041       0.260, 0.419    \n5,000   1        0.339      0.041       0.260, 0.419    \n\n\ntime    n.risk   estimate   std.error   95% CI          \n1,000   171      0.034      0.013       0.015, 0.066    \n2,000   103      0.050      0.016       0.026, 0.087    \n3,000   54       0.058      0.017       0.030, 0.099    \n4,000   13       0.106      0.032       0.053, 0.179    \n5,000   1        0.106      0.032       0.053, 0.179    \n\n\nWe can use the ggcuminc() function from the {ggsurvfit} package to plot the cumulative incidence. By default it plots the first event type only. So the following plot shows the cumulative incidence of death from melanoma:\n\ncuminc(Surv(time, status) ~ 1, data = Melanoma) |&gt; \n  ggcuminc() + \n  labs(\n    x = \"Days\"\n  ) + \n  add_confidence_interval() +\n  add_risktable()\n\n\n\n\n\n\n\n\nIf we want to include both event types, specify the outcomes in the ggcuminc(outcome=) argument:\n\ncuminc(Surv(time, status) ~ 1, data = Melanoma) |&gt; \n  ggcuminc(outcome = c(\"1\", \"2\")) +\n  ylim(c(0, 1)) + \n  labs(\n    x = \"Days\"\n  )\n\n\n\n\n\n\n\n\nNow let’s say we wanted to examine death from melanoma or other causes in the Melanoma data, according to ulcer, the presence or absence of ulceration. We can estimate the cumulative incidence at various times by group and display that in a table using the tbl_cuminc() function from the {tidycmprsk} package, and add Gray’s test to test for a difference between groups over the entire follow-up period using the add_p() function.\n\ncuminc(Surv(time, status) ~ ulcer, data = Melanoma) |&gt; \n  tbl_cuminc(\n    times = 1826.25, \n    label_header = \"**{time/365.25}-year cuminc**\") |&gt; \n  add_p()\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\n5-year cuminc\np-value1\n\n\n\n\nulcer\n\n\n&lt;0.001\n\n\n0\n9.1% (4.6%, 15%)\n\n\n\n\n1\n39% (29%, 49%)\n\n\n\n\n\n1 Gray’s Test\n\n\n\n\n\n\n\n\n\nThen we can see the plot of death due to melanoma, according to ulceration status, as before using ggcuminc() from the {ggsurvfit} package:\n\ncuminc(Surv(time, status) ~ ulcer, data = Melanoma) |&gt; \n  ggcuminc() + \n  labs(\n    x = \"Days\"\n  ) + \n  add_confidence_interval() +\n  add_risktable()"
  },
  {
    "objectID": "survival-analysis-in-r.html#competing-risks-regression",
    "href": "survival-analysis-in-r.html#competing-risks-regression",
    "title": "Survival analysis in R",
    "section": "Competing risks regression",
    "text": "Competing risks regression\nThere are two approaches to competing risks regression:\n\nCause-specific hazards\n\ninstantaneous rate of occurrence of the given type of event in subjects who are currently event‐free\nestimated using Cox regression (coxph function)\n\nSubdistribution hazards\n\ninstantaneous rate of occurrence of the given type of event in subjects who have not yet experienced an event of that type\nestimated using Fine-Gray regression (crr function)\n\n\nLet’s say we’re interested in looking at the effect of age and sex on death from melanoma, with death from other causes as a competing event.\nThe crr() function from the {tidycmprsk} package will estimate the subdistribution hazards.\n\ncrr(Surv(time, status) ~ sex + age, data = Melanoma)\n\n\nVariable   Coef    SE      HR     95% CI       p-value    \nsex        0.588   0.272   1.80   1.06, 3.07   0.030      \nage        0.013   0.009   1.01   0.99, 1.03   0.18       \n\n\nAnd we can generate tables of formatted results using the tbl_regression() function from the {gtsummary} package, with the option exp = TRUE to obtain the hazard ratio estimates:\n\ncrr(Surv(time, status) ~ sex + age, data = Melanoma) |&gt; \n  tbl_regression(exp = TRUE)\n\n\n\n\n\n\n\nCharacteristic\nHR\n95% CI\np-value\n\n\n\n\nsex\n1.80\n1.06, 3.07\n0.030\n\n\nage\n1.01\n0.99, 1.03\n0.2\n\n\n\nAbbreviations: CI = Confidence Interval, HR = Hazard Ratio\n\n\n\n\n\n\n\n\n\nWe see that male sex (recall that 1=male, 0=female in these data) is significantly associated with increased hazard of death due to melanoma, whereas age was not significantly associated with death due to melanoma.\nAlternatively, if we wanted to use the cause-specific hazards regression approach, we first need to censor all subjects who didn’t have the event of interest, in this case death from melanoma, and then use coxph as before. So patients who died from other causes are now censored for the cause-specific hazard approach to competing risks. Again we generate a table of formatted results using the tbl_regression() function from the {gtsummary} package:\n\ncoxph(\n  Surv(time, ifelse(status == 1, 1, 0)) ~ sex + age, \n  data = Melanoma\n  ) |&gt; \n  tbl_regression(exp = TRUE)\n\n\n\n\n\n\n\nCharacteristic\nHR\n95% CI\np-value\n\n\n\n\nsex\n1.82\n1.08, 3.07\n0.025\n\n\nage\n1.02\n1.00, 1.03\n0.056\n\n\n\nAbbreviations: CI = Confidence Interval, HR = Hazard Ratio\n\n\n\n\n\n\n\n\n\nAnd in this case we obtain similar results using the two approaches to competing risks regression."
  },
  {
    "objectID": "survival-analysis-in-r.html#assessing-proportional-hazards",
    "href": "survival-analysis-in-r.html#assessing-proportional-hazards",
    "title": "Survival analysis in R",
    "section": "Assessing proportional hazards",
    "text": "Assessing proportional hazards\nOne assumption of the Cox proportional hazards regression model is that the hazards are proportional at each point in time throughout follow-up. The cox.zph() function from the {survival} package allows us to check this assumption. It results in two main things:\n\nA hypothesis test of whether the effect of each covariate differs according to time, and a global test of all covariates at once.\n\nThis is done by testing for an interaction effect between the covariate and log(time)\nA significant p-value indicates that the proportional hazards assumption is violated\n\nPlots of the Schoenfeld residuals\n\nDeviation from a zero-slope line is evidence that the proportional hazards assumption is violated\n\n\n\nmv_fit &lt;- coxph(Surv(time, status) ~ sex + age, data = lung)\ncz &lt;- cox.zph(mv_fit)\nprint(cz)\n\n       chisq df    p\nsex    2.608  1 0.11\nage    0.209  1 0.65\nGLOBAL 2.771  2 0.25\n\nplot(cz)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHere we see that with p-values &gt;0.05, we do not reject the null hypothesis, and conclude that the proportional hazards assumption is satisfied for each individual covariate, and also for the model overall."
  },
  {
    "objectID": "survival-analysis-in-r.html#smooth-survival-plot",
    "href": "survival-analysis-in-r.html#smooth-survival-plot",
    "title": "Survival analysis in R",
    "section": "Smooth survival plot",
    "text": "Smooth survival plot\nSometimes you will want to visualize a survival estimate according to a continuous variable. The sm.survival function from the sm package allows you to do this for a quantile of the distribution of survival data. The default quantile is p = 0.5 for median survival.\n\n# install.packages(\"sm\")\nlibrary(sm)\n\nsm.options(\n  list(\n    xlab = \"Age (years)\",\n    ylab = \"Median time to death (years)\")\n  )\n\nsm.survival(\n  x = lung$age,\n  y = lung$time,\n  status = lung$status,\n  h = sd(lung$age) / nrow(lung)^(-1/4)\n  )\n\n\n\n\n\n\n\n\n\nThe x’s represent events\nThe o’s represent censoring\nThe line is a smoothed estimate of median survival according to age\n\nIn this case, too smooth!\n\n\nThe option h is the smoothing parameter. This should be related to the standard deviation of the continuous covariate, \\(x\\). Suggested to start with \\(\\frac{sd(x)}{n^{-1/4}}\\) then reduce by \\(1/2\\), \\(1/4\\), etc to get a good amount of smoothing. The previous plot was too smooth so let’s reduce it by \\(1/6\\):\n\nsm.survival(\n  x = lung$age,\n  y = lung$time,\n  status = lung$status,\n  h = (1/6) * sd(lung$age) / nrow(lung)^(-1/4)\n  )\n\n\n\n\n\n\n\n\nNow we can see that median time to death decreases slightly as age increases."
  },
  {
    "objectID": "survival-analysis-in-r.html#conditional-survival",
    "href": "survival-analysis-in-r.html#conditional-survival",
    "title": "Survival analysis in R",
    "section": "Conditional survival",
    "text": "Conditional survival\nSometimes it is of interest to generate survival estimates among a group of patients who have already survived for some length of time.\n\\[S(y|x) = \\frac{S(x + y)}{S(x)}\\]\n\n\\(y\\): number of additional survival years of interest\n\\(x\\): number of years a patient has already survived\n\n\nZabor, E., Gonen, M., Chapman, P., & Panageas, K. (2013). Dynamic prognostication using conditional survival estimates. Cancer, 119(20), 3589-3592.\n\nThe estimates are easy to generate with basic math on your own, and are also implemented in the {condsurv} package available from https://github.com/zabore/condsurv.\nWe can use the conditional_surv_est() function from the {condsurv} package to get estimates and 95% confidence intervals. Let’s condition on survival to 6-months\n\nfit1 &lt;- survfit(Surv(time, status) ~ 1, data = lung)\n\nprob_times &lt;- seq(365.25, 182.625 * 4, 182.625)\n\npurrr::map_df(\n  prob_times, \n  ~conditional_surv_est(\n    basekm = fit1, \n    t1 = 182.625, \n    t2 = .x) \n  ) |&gt; \n  mutate(months = round(prob_times / 30.4)) |&gt; \n  select(months, everything()) |&gt; \n  kable()\n\n\n\n\nmonths\ncs_est\ncs_lci\ncs_uci\n\n\n\n\n12\n0.58\n0.49\n0.66\n\n\n18\n0.36\n0.27\n0.45\n\n\n24\n0.16\n0.10\n0.25\n\n\n\n\n\nRecall that our initial \\(1\\)-year survival estimate was 0.41. We see that for patients who have already survived 12 months this increases to 0.58.\nWe can also visualize conditional survival data based on different lengths of time survived using the condKMggplot() function from the {condsurv} package:\n\ngg_conditional_surv(\n  basekm = fit1, \n  at = prob_times,\n  main = \"Conditional survival in lung data\",\n  xlab = \"Days\"\n  ) +\n  labs(color = \"Conditional time\")\n\n\n\n\n\n\n\n\nThe resulting plot has one survival curve for each time on which we condition. In this case the first line is the overall survival curve since it is conditioning on time 0."
  },
  {
    "objectID": "talks/2024-rladies-philly/slides.html#hello",
    "href": "talks/2024-rladies-philly/slides.html#hello",
    "title": "Introduction to Survival Analysis in R",
    "section": "Hello",
    "text": "Hello\n\n\nWho am I\nAssociate Staff Biostatistician at the Cleveland Clinic in the Department of Quantitative Health Sciences and the Taussig Cancer Institute.\nApplied cancer biostatistics and methods research in early phase oncology clinical trial design and methods for retrospective data analysis.\n\nWhy am I here\nSometimes, despite the actual focus of your career, you end up best known for a website post on survival analysis in R that you made for an internal training back in 2018 🤷.\nFull tutorial is available on my website."
  },
  {
    "objectID": "talks/2024-rladies-philly/slides.html#what-are-survival-data-anyway",
    "href": "talks/2024-rladies-philly/slides.html#what-are-survival-data-anyway",
    "title": "Introduction to Survival Analysis in R",
    "section": "What are survival data anyway?",
    "text": "What are survival data anyway?"
  },
  {
    "objectID": "talks/2024-rladies-philly/slides.html#examples-from-cancer",
    "href": "talks/2024-rladies-philly/slides.html#examples-from-cancer",
    "title": "Introduction to Survival Analysis in R",
    "section": "Examples from cancer",
    "text": "Examples from cancer\n\nTime from diagnosis to death\nTime from surgery to recurrence of disease\nTime from start of treatment to progression of disease\nTime from response to recurrence of disease"
  },
  {
    "objectID": "talks/2024-rladies-philly/slides.html#examples-from-other-fields",
    "href": "talks/2024-rladies-philly/slides.html#examples-from-other-fields",
    "title": "Introduction to Survival Analysis in R",
    "section": "Examples from other fields",
    "text": "Examples from other fields\n\nTime from HIV infection to development of AIDS\nTime to from diagnosis with heart disease to heart attack\nTime from dicharge from rehabilitation facility to recurrence of substance abuse\nTime from birth to initiation of sexual activity\nTime from production to machine malfunction"
  },
  {
    "objectID": "talks/2024-rladies-philly/slides.html#a-rose-by-any-other-name",
    "href": "talks/2024-rladies-philly/slides.html#a-rose-by-any-other-name",
    "title": "Introduction to Survival Analysis in R",
    "section": "A rose by any other name…",
    "text": "A rose by any other name…\nBecause time-to-event data are common in many fields, it also goes by names besides survival analysis including:\n\n\n\nReliability analysis\nDuration analysis\nEvent history analysis\nTime-to-event analysis"
  },
  {
    "objectID": "talks/2024-rladies-philly/slides.html#what-is-censoring",
    "href": "talks/2024-rladies-philly/slides.html#what-is-censoring",
    "title": "Introduction to Survival Analysis in R",
    "section": "What is censoring?",
    "text": "What is censoring?\n\nCensoring occurs when the event of interest is not observed after a period of follow-up"
  },
  {
    "objectID": "talks/2024-rladies-philly/slides.html#but-isnt-this-just-binary-data",
    "href": "talks/2024-rladies-philly/slides.html#but-isnt-this-just-binary-data",
    "title": "Introduction to Survival Analysis in R",
    "section": "But isn’t this just binary data??",
    "text": "But isn’t this just binary data??\n\nBinary data doesn’t have the ability to change depending on the time of analysis, e.g. 5-year survival will have the same value whether it is analyzed at 5 years and 1 day, 5 years and 2 days, 6 years, etc. Either a participant died by 5 years or they didn’t.\nTime-to-event data may have different values depending on the time of analysis, e.g. overall survival will have different values depending on whether it is analyzed at 5 years and 1 day or at 6 years, since additional participants can die between those two time points."
  },
  {
    "objectID": "talks/2024-rladies-philly/slides.html#right-censoring-example",
    "href": "talks/2024-rladies-philly/slides.html#right-censoring-example",
    "title": "Introduction to Survival Analysis in R",
    "section": "Right censoring example",
    "text": "Right censoring example"
  },
  {
    "objectID": "talks/2024-rladies-philly/slides.html#reasons-for-censoring",
    "href": "talks/2024-rladies-philly/slides.html#reasons-for-censoring",
    "title": "Introduction to Survival Analysis in R",
    "section": "Reasons for censoring",
    "text": "Reasons for censoring\nA subject may be censored due to:\n\nLoss to follow-up\nWithdrawal from study\nNo event by end of fixed study period"
  },
  {
    "objectID": "talks/2024-rladies-philly/slides.html#other-types-of-censoring",
    "href": "talks/2024-rladies-philly/slides.html#other-types-of-censoring",
    "title": "Introduction to Survival Analysis in R",
    "section": "Other types of censoring",
    "text": "Other types of censoring\n\n\nLeft censoring: when the event or censoring occurred before a study has started or data is collected\nInterval censoring: when the event or censoring occurred between two dates but when is not known exactly\n\nCommon in cancer studies where, for example, disease recurrence can only be detected by imaging, but the actual recurrence is known to have developed some time between the prior negative imaging and the current positive imaging\n\n\nToday we will focus only on right censoring."
  },
  {
    "objectID": "talks/2024-rladies-philly/slides.html#recall-this-plot",
    "href": "talks/2024-rladies-philly/slides.html#recall-this-plot",
    "title": "Introduction to Survival Analysis in R",
    "section": "Recall this plot",
    "text": "Recall this plot"
  },
  {
    "objectID": "talks/2024-rladies-philly/slides.html#censoring-must-be-considered-in-the-analysis",
    "href": "talks/2024-rladies-philly/slides.html#censoring-must-be-considered-in-the-analysis",
    "title": "Introduction to Survival Analysis in R",
    "section": "Censoring must be considered in the analysis",
    "text": "Censoring must be considered in the analysis\n\nHow would we compute the proportion who are event-free at 15 years?\n\nSubjects 7, 8, and 10 had the event before 15 years\nSubjects 1 and 9 were censored before 15 years\nThe remaining subjects were event-free and still being followed at 15 years\n\nAnd how would you compute the median time-to-event when the event time is unknown for some patients?"
  },
  {
    "objectID": "talks/2024-rladies-philly/slides.html#additional-reasons-for-survival-analysis",
    "href": "talks/2024-rladies-philly/slides.html#additional-reasons-for-survival-analysis",
    "title": "Introduction to Survival Analysis in R",
    "section": "Additional reasons for survival analysis",
    "text": "Additional reasons for survival analysis\n\n\n\n\n\n\n\n\n\n\n\n\n\nDistribution of follow-up times is skewed\nDistribution may differ between censored and event patients\nFollow-up times are always positive"
  },
  {
    "objectID": "talks/2024-rladies-philly/slides.html#data-components-for-survival-analysis",
    "href": "talks/2024-rladies-philly/slides.html#data-components-for-survival-analysis",
    "title": "Introduction to Survival Analysis in R",
    "section": "Data components for survival analysis",
    "text": "Data components for survival analysis\nTo analyze survival data, we need to know the observed time (\\(Y_i\\)) and the event indicator (\\(\\delta_i\\)). For a subject (denoted by \\(i\\)):\n\nObserved time is the minimum of the event time (\\(T_i\\)) and censoring time (\\(C_i\\)) (\\(Y_i = \\min(T_i, C_i)\\))\nEvent indicator (\\(\\delta_i\\)) is 1 if the event is observed (i.e. \\(T_i \\leq C_i\\)) and 0 if censored (i.e. \\(T_i &gt; C_i\\))"
  },
  {
    "objectID": "talks/2024-rladies-philly/slides.html#load-needed-packages",
    "href": "talks/2024-rladies-philly/slides.html#load-needed-packages",
    "title": "Introduction to Survival Analysis in R",
    "section": "Load needed packages",
    "text": "Load needed packages\n\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(lubridate)\nlibrary(survival)\nlibrary(ggsurvfit)\nlibrary(gtsummary)"
  },
  {
    "objectID": "talks/2024-rladies-philly/slides.html#load-example-data",
    "href": "talks/2024-rladies-philly/slides.html#load-example-data",
    "title": "Introduction to Survival Analysis in R",
    "section": "Load example data",
    "text": "Load example data\nTo access the example data used throughout this talk, install and load the cancersimdata package from my GitHub repo:\n\n# If needed, install the remotes package first\ninstall.packages(\"remotes\")\n\n# Then install the GitHub repository for the dataset\nremotes::install_github(\"zabore/cancersimdata\")\n\n# Finally, load the repository\nlibrary(cancersimdata)"
  },
  {
    "objectID": "talks/2024-rladies-philly/slides.html#example-data-background",
    "href": "talks/2024-rladies-philly/slides.html#example-data-background",
    "title": "Introduction to Survival Analysis in R",
    "section": "Example data background",
    "text": "Example data background\nbc_rt_data is a synthetic dataset based on real breast cancer data. The dataset contains information on 3000 women with T1-2N1M0 breast cancer, who had a mastectomy between 1995-2015.\nThe original study examined the association between post-mastectomy radiation therapy and disease recurrence.\n\n\nSittenfeld SMC, Zabor EC, …, Tendulkar RD. A multi-institutional prediction model to estimate the risk of recurrence and mortality after mastectomy for T1-2N1 breast cancer. Cancer. 2022 Aug 15;128(16):3057-3066. doi: 10.1002/cncr.34352. Epub 2022 Jun 17. PMID: 35713598; PMCID: PMC9539507."
  },
  {
    "objectID": "talks/2024-rladies-philly/slides.html#example-data-contents",
    "href": "talks/2024-rladies-philly/slides.html#example-data-contents",
    "title": "Introduction to Survival Analysis in R",
    "section": "Example data contents",
    "text": "Example data contents\nRelevant variables include:\n\nrt: PMRT indicator, 1 = yes, 0 = no\nos_event: Death indicator, 1 = dead, 0 = censored\ndate_of_mastecomy: Date of mastectomy\ndate_last_follow_up_death: Date of last follow-up or death"
  },
  {
    "objectID": "talks/2024-rladies-philly/slides.html#example-data-format",
    "href": "talks/2024-rladies-philly/slides.html#example-data-format",
    "title": "Introduction to Survival Analysis in R",
    "section": "Example data format",
    "text": "Example data format\n\nbc_rt_data |&gt; \n  select(rt, os_event, date_of_mastectomy, date_last_follow_up_death) |&gt; \n  print(n = 10)\n\n# A tibble: 3,000 × 4\n      rt os_event date_of_mastectomy date_last_follow_up_death\n   &lt;dbl&gt;    &lt;dbl&gt; &lt;chr&gt;              &lt;chr&gt;                    \n 1     0        0 09/11/2004         07/24/2009               \n 2     0        0 08/06/2011         11/07/2016               \n 3     0        0 06/10/1998         11/04/2005               \n 4     1        0 10/06/2013         04/30/2019               \n 5     1        0 11/22/2002         01/17/2008               \n 6     0        0 01/31/2013         01/12/2019               \n 7     1        0 05/03/2014         08/23/2016               \n 8     0        0 02/16/1998         11/12/2004               \n 9     1        0 03/04/2014         02/07/2020               \n10     1        1 03/06/1998         09/08/2003               \n# ℹ 2,990 more rows"
  },
  {
    "objectID": "talks/2024-rladies-philly/slides.html#event-indicator",
    "href": "talks/2024-rladies-philly/slides.html#event-indicator",
    "title": "Introduction to Survival Analysis in R",
    "section": "Event indicator",
    "text": "Event indicator\nIt is important to pay attention to the format of the event indicator.\nThe Surv() function in the survival package accepts by default TRUE/FALSE, where TRUE is event and FALSE is censored; 1/0 where 1 is event and 0 is censored; or 2/1 where 2 is event and 1 is censored. Please take care to ensure the event indicator is properly formatted.\nHere we see that the documentation stipulates 1 is event (death) and 0 is censored."
  },
  {
    "objectID": "talks/2024-rladies-philly/slides.html#start-and-end-dates",
    "href": "talks/2024-rladies-philly/slides.html#start-and-end-dates",
    "title": "Introduction to Survival Analysis in R",
    "section": "Start and end dates",
    "text": "Start and end dates\nHere, the start and end dates are in the dataset, formatted as character variables.\nWe need to:\n\nConvert them to date format\nCalculate the follow-up times"
  },
  {
    "objectID": "talks/2024-rladies-philly/slides.html#formatting-dates",
    "href": "talks/2024-rladies-philly/slides.html#formatting-dates",
    "title": "Introduction to Survival Analysis in R",
    "section": "Formatting dates",
    "text": "Formatting dates\nThe lubridate package offers a more comprehensive and user-friendly suite of functions for date manipulation. See the lubridate website for details.\nThe mdy() function converts character values ordered month day year:\n\nbc_rt_data &lt;- \n  bc_rt_data |&gt; \n  mutate(\n    date_of_mastectomy = mdy(date_of_mastectomy), \n    date_last_follow_up_death = mdy(date_last_follow_up_death)\n  )"
  },
  {
    "objectID": "talks/2024-rladies-philly/slides.html#formatted-dates",
    "href": "talks/2024-rladies-philly/slides.html#formatted-dates",
    "title": "Introduction to Survival Analysis in R",
    "section": "Formatted dates",
    "text": "Formatted dates\n\nbc_rt_data |&gt; \n  select(rt, os_event, date_of_mastectomy, date_last_follow_up_death) |&gt; \n  print(n = 10)\n\n# A tibble: 3,000 × 4\n      rt os_event date_of_mastectomy date_last_follow_up_death\n   &lt;dbl&gt;    &lt;dbl&gt; &lt;date&gt;             &lt;date&gt;                   \n 1     0        0 2004-09-11         2009-07-24               \n 2     0        0 2011-08-06         2016-11-07               \n 3     0        0 1998-06-10         2005-11-04               \n 4     1        0 2013-10-06         2019-04-30               \n 5     1        0 2002-11-22         2008-01-17               \n 6     0        0 2013-01-31         2019-01-12               \n 7     1        0 2014-05-03         2016-08-23               \n 8     0        0 1998-02-16         2004-11-12               \n 9     1        0 2014-03-04         2020-02-07               \n10     1        1 1998-03-06         2003-09-08               \n# ℹ 2,990 more rows"
  },
  {
    "objectID": "talks/2024-rladies-philly/slides.html#calculating-follow-up-times",
    "href": "talks/2024-rladies-philly/slides.html#calculating-follow-up-times",
    "title": "Introduction to Survival Analysis in R",
    "section": "Calculating follow-up times",
    "text": "Calculating follow-up times\n%--% is a special operator that creates an interval from a specific instant to another instant.\ndyears(1) converts the interval to be on the years scale\n\nbc_rt_data &lt;-\n  bc_rt_data |&gt; \n  mutate(\n    os_years = (date_of_mastectomy %--% date_last_follow_up_death) / dyears(1)\n  )\n\n\n\nNote that os_years is already a variable in this dataset, and we are simply overwriting it here with our own calculation, for demonstration purposes"
  },
  {
    "objectID": "talks/2024-rladies-philly/slides.html#checking-follow-up-times",
    "href": "talks/2024-rladies-philly/slides.html#checking-follow-up-times",
    "title": "Introduction to Survival Analysis in R",
    "section": "Checking follow-up times",
    "text": "Checking follow-up times\nIn real-world data it is common to encounter errors in data, such as end dates that come before start dates, etc.\nTypically as a quick check, I look at the numeric and visual distribution of follow-up times."
  },
  {
    "objectID": "talks/2024-rladies-philly/slides.html#checking-follow-up-times-1",
    "href": "talks/2024-rladies-philly/slides.html#checking-follow-up-times-1",
    "title": "Introduction to Survival Analysis in R",
    "section": "Checking follow-up times",
    "text": "Checking follow-up times\n\nsummary(bc_rt_data$os_years)\n\n    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. \n 0.02464  4.46749  6.35729  6.56711  8.55852 21.26489 \n\n\n\nggplot(bc_rt_data, aes(x = os_years, fill = factor(os_event))) +\n  geom_histogram(bins = 25, alpha = 0.5, position = \"identity\")"
  },
  {
    "objectID": "talks/2024-rladies-philly/slides.html#the-survival-package",
    "href": "talks/2024-rladies-philly/slides.html#the-survival-package",
    "title": "Introduction to Survival Analysis in R",
    "section": "The survival package",
    "text": "The survival package\nThe basis of the survival ecosystem in R.\n\n\n\n\n\n\n\nBegan development in 1985\nTotal of 11.9M downloads\nActive development ongoing\nMany detailed vignettes covering both the basics and advanced topics\nIncludes the essential methods"
  },
  {
    "objectID": "talks/2024-rladies-philly/slides.html#the-gtsummary-package",
    "href": "talks/2024-rladies-philly/slides.html#the-gtsummary-package",
    "title": "Introduction to Survival Analysis in R",
    "section": "The gtsummary package",
    "text": "The gtsummary package\n\nCreate highly customizable tables, see https://www.danieldsjoberg.com/gtsummary/ for details.\n\n\n\n\n\n\nUse tbl_survfit() to create:\n\nTables of median event-free time\nTables of x-time event-free probability\n\nUse tbl_uvregression() to create:\n\nTables of univariate Cox regression results\n\nUse tbl_regression() to create:\n\nTables of multivariable Cox regression results"
  },
  {
    "objectID": "talks/2024-rladies-philly/slides.html#the-ggsurvfit-package",
    "href": "talks/2024-rladies-philly/slides.html#the-ggsurvfit-package",
    "title": "Introduction to Survival Analysis in R",
    "section": "The ggsurvfit package",
    "text": "The ggsurvfit package\n\nUses ggplot2 as the basis so known customizations are available with the + operator. See https://www.danieldsjoberg.com/ggsurvfit/ for details.\n\n\n\n\n\n\n\nPlot Kaplan-Meier curves using ggsurvfit\nPlot cumulative incidence curves for competing risks using ggcuminc\nPlot multi-state models using ggsurvfit\nOptions to add confidence intervals, risk tables, quantiles, and more"
  },
  {
    "objectID": "talks/2024-rladies-philly/slides.html#packages-in-summary",
    "href": "talks/2024-rladies-philly/slides.html#packages-in-summary",
    "title": "Introduction to Survival Analysis in R",
    "section": "Packages, in summary",
    "text": "Packages, in summary"
  },
  {
    "objectID": "talks/2024-rladies-philly/slides.html#survival-object",
    "href": "talks/2024-rladies-philly/slides.html#survival-object",
    "title": "Introduction to Survival Analysis in R",
    "section": "Survival object",
    "text": "Survival object\nThe Surv() function creates a survival object for use as the response in a model formula. There is one value for each subject that is the survival time, followed by a + if the subject was censored.\n\n\n [1] 4.865161+ 5.256674+ 7.403149+ 5.563313+ 5.152635+ 5.946612+ 2.308008+\n [8] 6.737851+ 5.930185+ 5.508556 \n\n\nWe see that that the first 9 subjects were censored at variaous times, and the 10th subject had an event at 5.5 years."
  },
  {
    "objectID": "talks/2024-rladies-philly/slides.html#kaplan-meier",
    "href": "talks/2024-rladies-philly/slides.html#kaplan-meier",
    "title": "Introduction to Survival Analysis in R",
    "section": "Kaplan-Meier",
    "text": "Kaplan-Meier\nThe Kaplan-Meier method is the most common way to estimate survival times and probabilities. It is a non-parametric approach that results in a step function, where there is a step down each time an event occurs."
  },
  {
    "objectID": "talks/2024-rladies-philly/slides.html#survival-curves",
    "href": "talks/2024-rladies-philly/slides.html#survival-curves",
    "title": "Introduction to Survival Analysis in R",
    "section": "Survival curves",
    "text": "Survival curves\nThe survfit() function creates survival curves using the Kaplan-Meier method based on a formula.\n\ns1 &lt;- survfit(Surv(os_years, os_event) ~ 1, data = bc_rt_data)\n\nSome key components of this survfit object that will be used to create survival curves include:\n\ntime: the timepoints at which the curve has a step, i.e. at least one event occurred\nsurv: the survival probability estimate at the corresponding time"
  },
  {
    "objectID": "talks/2024-rladies-philly/slides.html#kaplan-meier-curves-with-ggsurvfit",
    "href": "talks/2024-rladies-philly/slides.html#kaplan-meier-curves-with-ggsurvfit",
    "title": "Introduction to Survival Analysis in R",
    "section": "Kaplan-Meier curves with ggsurvfit",
    "text": "Kaplan-Meier curves with ggsurvfit\nThe ggsurvfit package works best if you create the survfit object using the included survfit2() function, which uses the same syntax to what we saw previously with survfit().\nsurvfit2() tracks the environment from the function call, which allows the plot to have better default values for labeling and p-value reporting.\n\ns2 &lt;- survfit2(Surv(os_years, os_event) ~ 1, data = bc_rt_data)"
  },
  {
    "objectID": "talks/2024-rladies-philly/slides.html#plotting-the-curves",
    "href": "talks/2024-rladies-philly/slides.html#plotting-the-curves",
    "title": "Introduction to Survival Analysis in R",
    "section": "Plotting the curves",
    "text": "Plotting the curves\n\n\ns2 |&gt; \n  ggsurvfit() +\n  labs(\n    x = \"Years from mastectomy\",\n    y = \"Overall survival probability\"\n  ) + \n  scale_y_continuous(\n    limits = c(0, 1)) + \n  scale_x_continuous(\n    limits = c(0, 15), \n    breaks = seq(0, 15, 5)) + \n  add_confidence_interval() + \n  add_risktable(\n    risktable_stats = \"n.risk\")"
  },
  {
    "objectID": "talks/2024-rladies-philly/slides.html#add-confidence-intervals",
    "href": "talks/2024-rladies-philly/slides.html#add-confidence-intervals",
    "title": "Introduction to Survival Analysis in R",
    "section": "Add confidence intervals",
    "text": "Add confidence intervals\n\n\ns2 |&gt; \n  ggsurvfit() +\n  labs(\n    x = \"Years from mastectomy\",\n    y = \"Overall survival probability\"\n  ) + \n  scale_y_continuous(\n    limits = c(0, 1)) + \n  scale_x_continuous(\n    limits = c(0, 15), \n    breaks = seq(0, 15, 5)) + \n  add_confidence_interval() + \n  add_risktable(\n    risktable_stats = \"n.risk\")"
  },
  {
    "objectID": "talks/2024-rladies-philly/slides.html#add-risk-table",
    "href": "talks/2024-rladies-philly/slides.html#add-risk-table",
    "title": "Introduction to Survival Analysis in R",
    "section": "Add risk table",
    "text": "Add risk table\n\n\ns2 |&gt; \n  ggsurvfit() +\n  labs(\n    x = \"Years from mastectomy\",\n    y = \"Overall survival probability\"\n  ) + \n  scale_y_continuous(\n    limits = c(0, 1)) + \n  scale_x_continuous(\n    limits = c(0, 15), \n    breaks = seq(0, 15, 5)) + \n  add_confidence_interval() + \n  add_risktable(\n    risktable_stats = \"n.risk\")"
  },
  {
    "objectID": "talks/2024-rladies-philly/slides.html#survival-curves-common-mistakes",
    "href": "talks/2024-rladies-philly/slides.html#survival-curves-common-mistakes",
    "title": "Introduction to Survival Analysis in R",
    "section": "Survival curves: common mistakes",
    "text": "Survival curves: common mistakes\n\nPlotting the y-axis on a scale other than 0, 1\nPlotting the x-axis beyond the limit of reasonable confidence\nAdding too much extra information to plot face, e.g. hazard ratios, p-values, median survival time, etc\nUsing default/non-descriptive axis labels\nIgnoring negative or missing survival times"
  },
  {
    "objectID": "talks/2024-rladies-philly/slides.html#estimating-x-time-survival",
    "href": "talks/2024-rladies-philly/slides.html#estimating-x-time-survival",
    "title": "Introduction to Survival Analysis in R",
    "section": "Estimating x-time survival",
    "text": "Estimating x-time survival\n\nOne quantity of interest in a survival analysis is the probability of surviving beyond a certain point in time (x).\nFor example, to estimate the probability of surviving to 10 years, use summary with the times argument.\n\nsummary(survfit(Surv(os_years, os_event) ~ 1, data = bc_rt_data), times = 10)\n\nCall: survfit(formula = Surv(os_years, os_event) ~ 1, data = bc_rt_data)\n\n time n.risk n.event survival std.err lower 95% CI upper 95% CI\n   10    386     501    0.727  0.0125        0.703        0.752\n\n\nWe find that the 10-year probability of survival in this study is 73%.\nThe associated lower and upper bounds of the 95% confidence interval are also displayed."
  },
  {
    "objectID": "talks/2024-rladies-philly/slides.html#what-does-x-time-survival-mean",
    "href": "talks/2024-rladies-philly/slides.html#what-does-x-time-survival-mean",
    "title": "Introduction to Survival Analysis in R",
    "section": "What does x-time survival mean?",
    "text": "What does x-time survival mean?\nThe 10-year survival probability is the point on the y-axis that corresponds to 10 years on the x-axis for the survival curve."
  },
  {
    "objectID": "talks/2024-rladies-philly/slides.html#x-time-survival-common-mistakes",
    "href": "talks/2024-rladies-philly/slides.html#x-time-survival-common-mistakes",
    "title": "Introduction to Survival Analysis in R",
    "section": "x-time survival: common mistakes",
    "text": "x-time survival: common mistakes\n\nUsing a “naive” estimate:\n501 of the 3000 patients in the data died by 10 years so the “naive” estimate is calculated as:\n\\[\\Big(1 - \\frac{501}{3000}\\Big) \\times 100 = 83\\%\\] You get an incorrect estimate of the 10-year probability of survival when you ignore the fact that 2113 patients were censored before 10 years.\nRecall the correct estimate of the 10-year probability of survival, accounting for censoring using the Kaplan-Meier method, was 73%."
  },
  {
    "objectID": "talks/2024-rladies-philly/slides.html#illustration-overestimation-using-naive-estimate",
    "href": "talks/2024-rladies-philly/slides.html#illustration-overestimation-using-naive-estimate",
    "title": "Introduction to Survival Analysis in R",
    "section": "Illustration: overestimation using naive estimate",
    "text": "Illustration: overestimation using naive estimate\n\n\n\nIgnoring censoring leads to an overestimate of the overall survival probability. Censored subjects only contribute information for a portion of the follow-up time, and then fall out of the risk set, pulling down the cumulative probability of survival. Ignoring censoring erroneously treats patients who are censored as part of the risk set for the entire follow-up period."
  },
  {
    "objectID": "talks/2024-rladies-philly/slides.html#table-of-x-time-survival-probability",
    "href": "talks/2024-rladies-philly/slides.html#table-of-x-time-survival-probability",
    "title": "Introduction to Survival Analysis in R",
    "section": "Table of x-time survival probability",
    "text": "Table of x-time survival probability\nWe can produce nice tables of x-time survival probability estimates using the tbl_survfit() function from the gtsummary package:\n\n\nsurvfit(Surv(os_years, os_event) ~ 1, \n        data = bc_rt_data) |&gt; \n  tbl_survfit(\n    times = 10,\n    label_header = \n      \"**10-year survival (95% CI)**\"\n  )\n\n\n\n\n\n\n\n\nCharacteristic\n10-year survival (95% CI)\n\n\n\n\nOverall\n73% (70%, 75%)"
  },
  {
    "objectID": "talks/2024-rladies-philly/slides.html#estimating-median-survival-time",
    "href": "talks/2024-rladies-philly/slides.html#estimating-median-survival-time",
    "title": "Introduction to Survival Analysis in R",
    "section": "Estimating median survival time",
    "text": "Estimating median survival time\n\nAnother quantity of interest in a survival analysis is the average survival time, which we quantify using the median.\nNote that survival times are not expected to be normally distributed so the mean is not an appropriate summary.\nWe can obtain the median survival directly from the survfit object:\n\n\nCall: survfit(formula = Surv(os_years, os_event) ~ 1, data = bc_rt_data)\n\n        n events median 0.95LCL 0.95UCL\n[1,] 3000    526     NA      NA      NA\n\n\nWe see the median survival time is is NA, which means that it has not yet been reached in this study. This is common in scenarios when the event rate is low, or follow-up time is short."
  },
  {
    "objectID": "talks/2024-rladies-philly/slides.html#what-does-median-survival-mean",
    "href": "talks/2024-rladies-philly/slides.html#what-does-median-survival-mean",
    "title": "Introduction to Survival Analysis in R",
    "section": "What does median survival mean?",
    "text": "What does median survival mean?\nMedian survival is the time on the x-axis corresponding to a survival probability of 0.5 on the y-axis. Here we see there is no time where the horizontal line at 0.5 meets the survival curve."
  },
  {
    "objectID": "talks/2024-rladies-philly/slides.html#median-survival-common-mistakes",
    "href": "talks/2024-rladies-philly/slides.html#median-survival-common-mistakes",
    "title": "Introduction to Survival Analysis in R",
    "section": "Median survival: common mistakes",
    "text": "Median survival: common mistakes\nUsing a “naive” estimate.\nSummarize the median survival time among the 526 patients who died:\n\n\n# A tibble: 1 × 1\n  median_surv\n        &lt;dbl&gt;\n1        4.79\n\n\nYou get an incorrect estimate of median survival time of 4.8 years when you ignore the fact that censored patients also contribute follow-up time.\nRecall the correct estimate of median survival was not reached."
  },
  {
    "objectID": "talks/2024-rladies-philly/slides.html#illustration-underestimation-of-median-survival",
    "href": "talks/2024-rladies-philly/slides.html#illustration-underestimation-of-median-survival",
    "title": "Introduction to Survival Analysis in R",
    "section": "Illustration: underestimation of median survival",
    "text": "Illustration: underestimation of median survival\n\n\n\nIgnoring censoring leads to an underestimate of median survival time because the follow-up time that censored patients contribute is excluded, and the risk set is artificially small."
  },
  {
    "objectID": "talks/2024-rladies-philly/slides.html#table-of-median-survival",
    "href": "talks/2024-rladies-philly/slides.html#table-of-median-survival",
    "title": "Introduction to Survival Analysis in R",
    "section": "Table of median survival",
    "text": "Table of median survival\nWe can produce nice tables of median survival time estimates using the tbl_survfit() function from the gtsummary package:\n\n\nsurvfit(Surv(os_years, os_event) ~ 1, \n        data = bc_rt_data) |&gt; \n  tbl_survfit(\n    probs = 0.5,\n    label_header = \n      \"**Median survival (95% CI)**\"\n  )\n\n\n\n\n\n\n\n\nCharacteristic\nMedian survival (95% CI)\n\n\n\n\nOverall\n— (—, —)\n\n\n\n\n\n\n\n\n\nIn this case, this table is not informative, but is included for demonstration purposes. In a dataset like this where median survival is not reached, x-time estimates can be presented instead, sometimes for multiple timepoints"
  },
  {
    "objectID": "talks/2024-rladies-philly/slides.html#comparing-survival-times-between-groups",
    "href": "talks/2024-rladies-philly/slides.html#comparing-survival-times-between-groups",
    "title": "Introduction to Survival Analysis in R",
    "section": "Comparing survival times between groups",
    "text": "Comparing survival times between groups\n\nWe can conduct between-group significance tests using a log-rank test.\n\nThe log-rank test equally weights observations over the entire follow-up time and is the most common way to compare survival times between groups.\n\nThere are versions that more heavily weight the early or late follow-up that could be more appropriate depending on the research question (see ?survdiff for different test options)."
  },
  {
    "objectID": "talks/2024-rladies-philly/slides.html#conducting-the-log-rank-test",
    "href": "talks/2024-rladies-philly/slides.html#conducting-the-log-rank-test",
    "title": "Introduction to Survival Analysis in R",
    "section": "Conducting the log-rank test",
    "text": "Conducting the log-rank test\n\nWe get the log-rank p-value using the survdiff() function from the survival package. For example, we can test whether there was a difference in survival time according to PMRT:\n\nsurvdiff(Surv(os_years, os_event) ~ rt, data = bc_rt_data)\n\nCall:\nsurvdiff(formula = Surv(os_years, os_event) ~ rt, data = bc_rt_data)\n\nn=2823, 177 observations deleted due to missingness.\n\n        N Observed Expected (O-E)^2/E (O-E)^2/V\nrt=0 1147      233      195      7.55      12.7\nrt=1 1676      246      284      5.17      12.7\n\n Chisq= 12.7  on 1 degrees of freedom, p= 4e-04 \n\n\nWe see that there was a significant difference in overall survival according to PMRT, with a p-value of p = &lt;.001."
  },
  {
    "objectID": "talks/2024-rladies-philly/slides.html#add-log-rank-p-value-to-kaplan-meier-plot",
    "href": "talks/2024-rladies-philly/slides.html#add-log-rank-p-value-to-kaplan-meier-plot",
    "title": "Introduction to Survival Analysis in R",
    "section": "Add log-rank p-value to Kaplan-Meier plot",
    "text": "Add log-rank p-value to Kaplan-Meier plot\n\n\nsurvfit2(\n  Surv(os_years, os_event) ~ rt, \n  data = bc_rt_data) |&gt; \n  ggsurvfit() +\n  labs(\n    x = \"Years from mastectomy\",\n    y = \"Overall survival probability\"\n  ) + \n  scale_y_continuous(\n    limits = c(0, 1)) + \n  scale_x_continuous(\n    limits = c(0, 15), \n    breaks = seq(0, 15, 5)) + \n  add_risktable(\n    risktable_stats = \"n.risk\"\n    ) + \n  scale_color_manual(\n    values = ccf_palette(\"contrast\"),\n    labels = c(\"No RT\", \"RT\")\n  ) +\n  add_pvalue()"
  },
  {
    "objectID": "talks/2024-rladies-philly/slides.html#the-cox-regression-model",
    "href": "talks/2024-rladies-philly/slides.html#the-cox-regression-model",
    "title": "Introduction to Survival Analysis in R",
    "section": "The Cox regression model",
    "text": "The Cox regression model\nWe may want to quantify an effect size for a single variable, or include more than one variable into a regression model to account for the effects of multiple variables.\nThe Cox regression model is a semi-parametric model that can be used to fit univariate and multivariable regression models that have survival outcomes.\n\\[h(t|X_i) = h_0(t) \\exp(\\beta_1 X_{i1} + \\cdots + \\beta_p X_{ip})\\]\n\\(h(t)\\): hazard, or the instantaneous rate at which events occur \\(h_0(t)\\): underlying baseline hazard"
  },
  {
    "objectID": "talks/2024-rladies-philly/slides.html#cox-regression-assumptions",
    "href": "talks/2024-rladies-philly/slides.html#cox-regression-assumptions",
    "title": "Introduction to Survival Analysis in R",
    "section": "Cox regression assumptions",
    "text": "Cox regression assumptions\nSome key assumptions of the model:\n\nnon-informative censoring\nproportional hazards\n\nNote that parametric regression models for survival outcomes are also available, but they won’t be addressed in this tutorial."
  },
  {
    "objectID": "talks/2024-rladies-philly/slides.html#how-to-interpret-a-hazard-ratio",
    "href": "talks/2024-rladies-philly/slides.html#how-to-interpret-a-hazard-ratio",
    "title": "Introduction to Survival Analysis in R",
    "section": "How to interpret a hazard ratio",
    "text": "How to interpret a hazard ratio\nThe quantity of interest from a Cox regression model is a hazard ratio (HR), which represents the instantaneous rate of occurrence of the event of interest in those who are still at risk for the event.\n\nIf you have a regression parameter \\(\\beta\\), then HR = \\(\\exp(\\beta)\\).\n\nA HR &lt; 1 indicates reduced hazard of event whereas a HR &gt; 1 indicates an increased hazard of event."
  },
  {
    "objectID": "talks/2024-rladies-philly/slides.html#fitting-cox-models",
    "href": "talks/2024-rladies-philly/slides.html#fitting-cox-models",
    "title": "Introduction to Survival Analysis in R",
    "section": "Fitting Cox models",
    "text": "Fitting Cox models\nFit regression models using the coxph() function from the survival package, which takes a Surv() object on the left hand side and has standard syntax for regression formulas in R on the right hand side.\n\nmod1 &lt;- coxph(Surv(os_years, os_event) ~ rt, data = bc_rt_data)"
  },
  {
    "objectID": "talks/2024-rladies-philly/slides.html#table-of-cox-model-results",
    "href": "talks/2024-rladies-philly/slides.html#table-of-cox-model-results",
    "title": "Introduction to Survival Analysis in R",
    "section": "Table of Cox model results",
    "text": "Table of Cox model results\nWe can creates tables of results using the tbl_regression() function from the gtsummary package, with the option to exponentiate set to TRUE to return the hazard ratio rather than the log hazard ratio:\n\n\nmod1 |&gt; \n  tbl_regression(\n    exp = TRUE,\n    label = list(rt ~ \"PMRT\")\n    ) \n\n\n\n\n\n\n\n\nCharacteristic\nHR\n95% CI\np-value\n\n\n\n\nPMRT\n0.72\n0.60, 0.86\n&lt;0.001\n\n\n\nAbbreviations: CI = Confidence Interval, HR = Hazard Ratio\n\n\n\n\n\n\n\n\nHR = 0.72 implies that receipt of PMRT is associated with 0.72 times the hazard of death as compared to no PMRT."
  },
  {
    "objectID": "talks/2024-rladies-philly/slides.html#cox-regression-common-mistakes",
    "href": "talks/2024-rladies-philly/slides.html#cox-regression-common-mistakes",
    "title": "Introduction to Survival Analysis in R",
    "section": "Cox regression: common mistakes",
    "text": "Cox regression: common mistakes\n\nOverfitting. This occurs when there are too few events to support the number of included variables. Rule of thumb is 10-15 events per degree of freedom.\nInterpreting a hazard as a risk - they are related, but they are not the same.\nOverlooking the proportional hazards assumption"
  },
  {
    "objectID": "talks/2024-rladies-philly/slides.html#connect-with-me",
    "href": "talks/2024-rladies-philly/slides.html#connect-with-me",
    "title": "Introduction to Survival Analysis in R",
    "section": "Connect with me",
    "text": "Connect with me\n\n\n zabore2@ccf.org\n https://www.emilyzabor.com/\n https://github.com/zabore\n https://www.linkedin.com/in/emily-zabor-59b902b7/\n https://bsky.app/profile/zabore.bsky.social/"
  },
  {
    "objectID": "talks/2024-rladies-philly/slides.html#further-reading",
    "href": "talks/2024-rladies-philly/slides.html#further-reading",
    "title": "Introduction to Survival Analysis in R",
    "section": "Further reading",
    "text": "Further reading\n\n\nClark, T., Bradburn, M., Love, S., & Altman, D. (2003). Survival analysis part I: Basic concepts and first analyses. 232-238. ISSN 0007-0920.\n\n\nM J Bradburn, T G Clark, S B Love, & D G Altman. (2003). Survival Analysis Part II: Multivariate data analysis – an introduction to concepts and methods. British Journal of Cancer, 89(3), 431-436.\n\n\nBradburn, M., Clark, T., Love, S., & Altman, D. (2003). Survival analysis Part III: Multivariate data analysis – choosing a model and assessing its adequacy and fit. 89(4), 605-11.\n\n\nClark, T., Bradburn, M., Love, S., & Altman, D. (2003). Survival analysis part IV: Further concepts and methods in survival analysis. 781-786. ISSN 0007-0920."
  },
  {
    "objectID": "talks.html",
    "href": "talks.html",
    "title": "Talks",
    "section": "",
    "text": "Note that this page is a work in progress, mostly hosting slides from R talks prospectively. Many other slide decks from past talks are available on GitHub."
  },
  {
    "objectID": "talks.html#umass-chan-r-café-making-your-workflow-reproducible",
    "href": "talks.html#umass-chan-r-café-making-your-workflow-reproducible",
    "title": "Talks",
    "section": "UMass Chan R Café: Making your workflow reproducible",
    "text": "UMass Chan R Café: Making your workflow reproducible\n2025-10-24\n\nFull Screen"
  },
  {
    "objectID": "talks.html#r-ladies-philly-introduction-to-survival-analysis-in-r",
    "href": "talks.html#r-ladies-philly-introduction-to-survival-analysis-in-r",
    "title": "Talks",
    "section": "R-Ladies Philly: Introduction to Survival Analysis in R",
    "text": "R-Ladies Philly: Introduction to Survival Analysis in R\n2024-12-17\n\nFull Screen"
  },
  {
    "objectID": "talks/2025-umass-r-cafe/slides.html#using-starter-default-settings",
    "href": "talks/2025-umass-r-cafe/slides.html#using-starter-default-settings",
    "title": "Making your workflow reproducible",
    "section": "Using {starter}: default settings",
    "text": "Using {starter}: default settings\n\n# install.packages(\"starter\") \n\nstarter::create_project(\n  path = fs::path(tempdir(), \"My Project Folder\"),\n  open = FALSE # don't open project in new RStudio session\n)\n\n✔ Using \"Default Project Template\" template\n\n\n✔ Writing folder 'C:/Users/zabore2/AppData/Local/Temp/RtmpMTUbvb/My Project Folder'\n\n\n✔ Writing files \"README.md\", \".gitignore\", \"My Project Folder.Rproj\", and \".Rprofile\"\n\n\n✔ Initialising Git repo\n\n\n✔ Initialising renv project\n\n\n- Lockfile written to \"C:/Users/zabore2/AppData/Local/Temp/RtmpMTUbvb/My Project Folder/renv.lock\".\n- renv infrastructure has been generated for project \"C:/Users/zabore2/AppData/Local/Temp/RtmpMTUbvb/My Project Folder\"."
  },
  {
    "objectID": "talks/2025-umass-r-cafe/slides.html#using-starter-custom-template",
    "href": "talks/2025-umass-r-cafe/slides.html#using-starter-custom-template",
    "title": "Making your workflow reproducible",
    "section": "Using {starter}: custom template",
    "text": "Using {starter}: custom template\n\n# devtools::install_github(\"zabore/ezfun\") \n\nstarter::create_project(\n  path = fs::path(tempdir(), \"example-custom-project\"),\n  template = ezfun::ez_analysis_template,\n  open = FALSE\n)\n\n✔ Using \"EZ Analysis Template\" template\n\n\n✔ Writing folder 'C:/Users/zabore2/AppData/Local/Temp/RtmpMTUbvb/example-custom-project'\n\n\n✔ Creating 'C:/Users/zabore2/AppData/Local/Temp/RtmpMTUbvb/example-custom-project/code'\n\n\n✔ Creating 'C:/Users/zabore2/AppData/Local/Temp/RtmpMTUbvb/example-custom-project/code/templates'\n\n\n✔ Writing files \"README.md\", \".gitignore\", \"example-custom-project.Rproj\", \".Rprofile\", \"code/example-custom-project-munge.R\", \"code/example-custom-project-report.qmd\", and \"code/templates/doc_template.docx\"\n\n\n✔ Initialising Git repo\n\n\n✔ Initialising renv project\n\n\n- Lockfile written to \"C:/Users/zabore2/AppData/Local/Temp/RtmpMTUbvb/example-custom-project/renv.lock\".\n- renv infrastructure has been generated for project \"C:/Users/zabore2/AppData/Local/Temp/RtmpMTUbvb/example-custom-project\"."
  },
  {
    "objectID": "talks/2025-umass-r-cafe/slides.html#thank-you",
    "href": "talks/2025-umass-r-cafe/slides.html#thank-you",
    "title": "Making your workflow reproducible",
    "section": "Thank you",
    "text": "Thank you\n\nConnect with me:\n\n\n\n zabore2@ccf.org\n https://www.emilyzabor.com/\n https://github.com/zabore\n https://www.linkedin.com/in/emily-zabor-59b902b7/\n https://bsky.app/profile/zabore.bsky.social/"
  }
]